{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Web Scraping III -- API </center>\n",
    "\n",
    "References: \n",
    "https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Scrape data through API (e.g. tweets)\n",
    "- Online content providers usually provide APIs for you to access data. Two types of APIs:\n",
    "   * Python packages: e.g. tweepy package from Twitter\n",
    "   * REST APIs: e.g. OMDB APIs (https://developers.themoviedb.org/3/getting-started)\n",
    "- You need to read documentation of APIs to figure out how to access data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Access tweet stream (e.g. real-time tweets) through tweepy package\n",
    "- **Steam**: transmitting or receiving data as a steady, continuous flow (the opposite is **batch**)\n",
    "\n",
    "- Event **Listener**(or Event Handler): \n",
    "  - A procedure or function that waits for an event to occur.\n",
    "  - Event examples: a user clicking or moving the mouse, pressing a key on the keyboard, an internal timer, or a tweet arriving.\n",
    "  - A listener is in effect a loop that is programmed to react to an input or signal.\n",
    "  \n",
    "- Twitter Terminology (https://support.twitter.com/articles/166337)\n",
    "  - **@{username}**: mentioning an accounts {username} in a tweet\n",
    "  - **\\#{topic}**: a hashtag indicates a keyword or topic.\n",
    "  - **follow**: Subscribing to a Twitter account \n",
    "  - **reply**: A response to another person’s Tweet\n",
    "  - **Retweet (n.)**: A tweet that you forward to your followers\n",
    "  - **like (n.)**: indicates appreciating a tweet. \n",
    "  - **timeline**: A timeline is a real-time stream of tweets. Your Home timeline, for instance, is where you see all the Tweets shared by your friends and other people you follow.\n",
    "  - **Twitter emoji**: A Twitter emoji is a specific series of letters immediately preceded by the # sign which generates an icon on Twitter such as a national flag or another small image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.1 define a listener which listens to tweets in real time\n",
    "\n",
    "\n",
    "import tweepy\n",
    "# to install tweepy, use: pip install tweepy\n",
    "\n",
    "# import twitter authentication module\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "# import tweepy steam module\n",
    "from tweepy import Stream\n",
    "\n",
    "# import stream listener\n",
    "from tweepy.streaming import StreamListener\n",
    "\n",
    "# import the python package to handle datetime\n",
    "import datetime\n",
    "\n",
    "# set your keys to access tweets \n",
    "\n",
    "consumer_key = 'your consumer key'\n",
    "consumer_secret = 'consumer secret'\n",
    "access_token = 'your access token'\n",
    "access_secret = 'your access secret'\n",
    " \n",
    "    \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "# Customize a tweet event listener \n",
    "# inherited from StreamListener provided by tweepy\n",
    "# This listener reacts when a tweet arrives or an error happens\n",
    "# for details of class StreamListener, see https://github.com/tweepy/tweepy/blob/master/tweepy/streaming.py\n",
    "\n",
    "class MyListener(StreamListener):\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, output_file, time_limit):\n",
    "        \n",
    "            # attribute to get listener start time\n",
    "            self.start_time=datetime.datetime.now()\n",
    "            \n",
    "            # attribute to set time limit for listening\n",
    "            self.time_limit=time_limit\n",
    "            \n",
    "            # attribute to set the output file\n",
    "            self.output_file=output_file\n",
    "            \n",
    "            # initiate superclass's constructor\n",
    "            StreamListener.__init__(self)\n",
    "    \n",
    "    # on_data is invoked when a tweet comes in\n",
    "    # overwrite this method inheritted from superclass\n",
    "    # when a tweet comes in, the tweet is passed as \"data\"\n",
    "    def on_data(self, data):\n",
    "        \n",
    "        # get running time\n",
    "        running_time=datetime.datetime.now()-self.start_time\n",
    "        print(running_time)\n",
    "        \n",
    "        # check if running time is over time_limit\n",
    "        if running_time.seconds/60.0<self.time_limit:\n",
    "            \n",
    "            # ***Exception handling*** \n",
    "            # If an error is encountered, \n",
    "            # a try block code execution is stopped and transferred\n",
    "            # down to the except block. \n",
    "            # If there is no error, \"except\" block is ignored\n",
    "            try:\n",
    "                # open file in \"append\" mode\n",
    "                with open(self.output_file, 'a') as f:\n",
    "                    # Write tweet string (in JSON format) into a file\n",
    "                    f.write(data)\n",
    "                    \n",
    "                    # continue listening\n",
    "                    return True\n",
    "                \n",
    "            # if an error is encountered\n",
    "            # print out the error message and continue listening\n",
    "            \n",
    "            except BaseException as e:\n",
    "                print(\"Error on_data:\" , str(e))\n",
    "                \n",
    "                # if return \"True\", the listener continues\n",
    "                return True\n",
    "            \n",
    "        else:  # timeout, return False to stop the listener\n",
    "            print(\"time out\")\n",
    "            return False\n",
    " \n",
    "    # on_error is invoked if there is anything wrong with the listener\n",
    "    # error status is passed to this method\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        # continue listening by \"return True\"\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.2 Collect tweets with specific topics within 2 minute\n",
    "\n",
    "# initiate an instance of MyListener \n",
    "tweet_listener=MyListener(output_file=\"python.txt\",\\\n",
    "                          time_limit=1)\n",
    "\n",
    "# start a stream instance using authentication and the listener\n",
    "twitter_stream = Stream(auth, tweet_listener)\n",
    "# filtering tweets by topics\n",
    "twitter_stream.filter(\\\n",
    "track=['#blockchain', '#bitcoin','#crpytocurrency','#smartcontract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2.3. Collect 1% sample of all tweets within 30 seconds\n",
    "\n",
    "tweet_listener=MyListener(output_file=\"tweets.txt\",\\\n",
    "                          time_limit=0.5)\n",
    "twitter_stream = Stream(auth, tweet_listener)\n",
    "twitter_stream.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(datetime.datetime.now().date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.4. Collect historical tweets \n",
    "# (i.e. tweets happened in the last week ) for a topic\n",
    "\n",
    "tweets=[]\n",
    "max_tweets=500\n",
    "last_id = -1\n",
    "\n",
    "query='#blockchain'\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "while len(tweets) < max_tweets:\n",
    "    count = max_tweets - len(tweets)\n",
    "    try:\n",
    "        # for each search, at maximum you get 100 results, although\n",
    "        # you can set count larger than 100\n",
    "        # You can limit the id for the most recent tweets (max_id)\n",
    "        # query can be a list of hashtags\n",
    "        # search api returns tweets sorted by time in descending order\n",
    "        new_tweets = api.search(q=query, count=count, max_id=str(last_id - 1))\n",
    "        \n",
    "        if not new_tweets:\n",
    "            break\n",
    "\n",
    "        # extract (date, tweet text) of new tweets \n",
    "        tweets+=[(item.id, item.created_at, item.text) for item in new_tweets]\n",
    "        \n",
    "        # get the first tweet in the batch\n",
    "        last_id = new_tweets[-1].id\n",
    "\n",
    "    except tweepy.TweepError as e:\n",
    "        # depending on TweepError.code, one may want to retry or wait\n",
    "        # to keep things simple, we will give up on an error\n",
    "        break\n",
    "\n",
    "tweets\n",
    "\n",
    "# you can find tweets happened in the last week using\n",
    "# new_tweets = api.search(q=query, count=count, since=\"2018-10-01\", until=\"2018-10-02\", max_id=str(last_id - 1))\n",
    "# but it can retrieve tweets older than a week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.5. How to get all past tweets within a period of time? \n",
    "- You can always search tweets at https://twitter.com/search and then scrape the results returned\n",
    "- Note that there is **no authentication needed**!\n",
    "- Check github project, https://github.com/Jefferson-Henrique/GetOldTweets-pythonyou \n",
    "- Motivated by this project, let's try the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5.1. Scrape past tweets using API \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# User agent must be defined in http request header\n",
    "# a user agent is software that is acting on behalf of \n",
    "# a user. Usually it tells the browser used.\n",
    "headers = { 'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.'\n",
    "                              '86 Safari/537.36'}\n",
    "\n",
    "# specify parameters as a dictionary\n",
    "payload={\"f\":\"tweets\",  # retrieve tweets\n",
    "         \"q\":\"blockchain since:2017-09-10 until:2017-09-12\", # query string\n",
    "         \"max_position\":''} # max_position of results (paging purpose)\n",
    "\n",
    "# send a request with parameters and headers\n",
    "r=requests.get(\"https://twitter.com/i/search/timeline\",\\\n",
    "              params=payload, headers=headers)\n",
    "\n",
    "if r.status_code==200:\n",
    "    result=r.json()\n",
    "    print(result)\n",
    "    \n",
    "    # retrieve the position of last tweet\n",
    "    min_position = result['min_position']\n",
    "    \n",
    "    # get html source code of tweets\n",
    "    tweets_html = result['items_html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.5.2. define a function to parse tweets html \n",
    "# using BeautifulSoup\n",
    "\n",
    "def getTweets(tweets_html):\n",
    "    \n",
    "    result=[]\n",
    "    \n",
    "    soup=BeautifulSoup(tweets_html, \"html.parser\")\n",
    "\n",
    "    tweets=soup.select('div.js-stream-tweet')\n",
    "\n",
    "    for t in tweets:\n",
    "        username, text, timestamp, tweet_id = '','','',''\n",
    "        select_user = t.select(\"span.username.u-dir b\")\n",
    "        if select_user!=[]:\n",
    "            username=select_user[0].get_text()\n",
    "    \n",
    "        select_text = t.select(\"p.js-tweet-text\")\n",
    "        if select_text!=[]:\n",
    "            text=select_text[0].get_text()\n",
    "    \n",
    "        time_select = t.select(\"small.time span.js-short-timestamp\")\n",
    "        if time_select!=[]:\n",
    "            timestamp=int(time_select[0][\"data-time\"])\n",
    "            timestamp=datetime.datetime.fromtimestamp(timestamp)\n",
    "    \n",
    "        tweet_id = t[\"data-tweet-id\"]\n",
    "    \n",
    "        #print(username, text, timestamp, tweet_id, \"\\n\")\n",
    "        \n",
    "        result.append((username, text, timestamp, tweet_id))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5.3. Parse tweets using the function\n",
    "\n",
    "tweets=getTweets(tweets_html)\n",
    "print(\"total tweets:\", len(tweets))\n",
    "print(\"first tweet: \",tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 2.5.4. What if we want to return more?\n",
    "\n",
    "# set the max_position to \n",
    "# the min_position of last search\n",
    "payload={\"f\":\"tweets\",\\\n",
    "         \"q\":\"blockchain\",\\\n",
    "         \"since\":\"2017-09-10\",\\\n",
    "         \"until\":\"2017-09-12\",\\\n",
    "         \"max_position\":min_position} \n",
    "\n",
    "# search again\n",
    "r=requests.get(\"https://twitter.com/i/search/timeline\",\\\n",
    "              params=payload, headers=headers)\n",
    "#https://twitter.com/i/search/timeline?f=tweets&q=%20blockchain%20since%3A2017-09-10%20until%3A2017-09-12&src=typd&max_position=\n",
    "if r.status_code==200:\n",
    "    result=r.json()\n",
    "    min_position = result['min_position']\n",
    "    tweets_html = result['items_html']\n",
    "    \n",
    "    print(min_position)\n",
    "    \n",
    "    tweets=getTweets(tweets_html)\n",
    "    print(\"total tweets:\", len(tweets))\n",
    "    print(\"first tweet: \",tweets[0])\n",
    "    \n",
    "# You can use a loop to keep sending requests\n",
    "# until all tweets satisfying your criteria\n",
    "# has been fetched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. JSON (JavaScript Object Notation)\n",
    "\n",
    "### What is JSON\n",
    "- A lightweight data-interchange format\n",
    "- \"self-describing\" and easy to understand\n",
    "- the JSON format is text only \n",
    "- Language independent: can be read and used as a data format by any programming language\n",
    "\n",
    "###  JSON Syntax Rules\n",
    "JSON syntax is derived from JavaScript object notation syntax:\n",
    "- Data is in name/value pairs\n",
    "- Data is separated by commas\n",
    "- Curly braces hold objects\n",
    "- Square brackets hold arrays\n",
    "\n",
    "### A JSON file can be easily loaded into \n",
    "- **a dictionary** or \n",
    "- a **list of dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.1. Read/write JSON \n",
    "import json\n",
    "tweets=[]\n",
    "\n",
    "with open('python.txt', 'r') as f:\n",
    "    # each line is one tweet string in JSON format\n",
    "    for line in f: \n",
    "        \n",
    "        # load a string in JSON format as Python dictionary\n",
    "        tweet = json.loads(line) \n",
    "              \n",
    "        tweets.append(tweet)\n",
    "\n",
    "# write the whole list back to JSON\n",
    "json.dump(tweets, open(\"all_tweets.json\",'w'))\n",
    "\n",
    "# to load the whole list\n",
    "# pay attention to json.load and json.loads\n",
    "tweets=json.load(open(\"all_tweets.json\",'r'))\n",
    "\n",
    "# open \"all_tweets.json\" and \"python.txt\" to see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.2. Investigating a tweet\n",
    "\n",
    "# A tweet is a dictionary\n",
    "# Some values are dictionaries too!\n",
    "# for details, check https://dev.twitter.com/overview/api/tweets\n",
    "\n",
    "print(\"# of tweets:\", len(tweets))\n",
    "first_tweet=tweets[0]\n",
    "\n",
    "print(\"\\nprint out first tweet nicely:\")\n",
    "print(json.dumps(first_tweet, indent=4))   \n",
    "\n",
    "# note the difference between \"json.dumps()\" and \"json.dump()\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.3. Investigating attributes of a tweet\n",
    "\n",
    "print(\"tweet text:\", first_tweet[\"text\"] )\n",
    "# get all hashtags (i.e. topics) in this tweet\n",
    "      \n",
    "topics=[hashtag[\"text\"] for hashtag in first_tweet[\"entities\"][\"hashtags\"]]\n",
    "print(\"\\ntopics:\", topics)\n",
    "\n",
    "# get all user_mentions in this tweet\n",
    "user_mentions=[user_mention[\"screen_name\"] for user_mention in first_tweet[\"entities\"][\"user_mentions\"]]\n",
    "print(\"\\nusers mentioned:\", user_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.4. count tweets per topic\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# get the number of tweets for each topic as a dictionary\n",
    "count_per_topic={}\n",
    "\n",
    "# loop through each tweet in the list\n",
    "for t in tweets:\n",
    "    # check if \"entities\" exist and \"hashtags\" exist in \"entities\"\n",
    "    if \"entities\" in t and \"hashtags\" in t[\"entities\"]:\n",
    "        \n",
    "        # get all topics as a set (unique topics)\n",
    "        topics=set([hashtag[\"text\"].lower() for hashtag in t[\"entities\"][\"hashtags\"]])\n",
    "        \n",
    "        for topic in topics:\n",
    "            topic=topic.lower()\n",
    "            if topic in count_per_topic:\n",
    "                count_per_topic[topic]+=1\n",
    "            else:\n",
    "                count_per_topic[topic]=1\n",
    "        \n",
    "print(count_per_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.5. Visualize data\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# convert dictionary to dataframe\n",
    "# argument orient: {‘columns’, ‘index’} indicates \n",
    "# whether the keys are used as rows or columns\n",
    "\n",
    "df=pd.DataFrame.from_dict(count_per_topic, orient=\"index\" )\n",
    "df.columns=[\"count\"]\n",
    "\n",
    "df\n",
    "# how to get top 10 topics?\n",
    "\n",
    "# how to plot top 10 topics?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 4.6. Word Cloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\")\n",
    "wordcloud.generate_from_frequencies(frequencies=count_per_topic)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scrape data by REST APIs (e.g. OMDB API)\n",
    "- A REST API is a web service that uses HTTP requests to GET, PUT, POST and DELETE data\n",
    "- Experiment:\n",
    "    - Get an API key here: http://www.omdbapi.com/apikey.aspx and follow the instruction to activate the key\n",
    "    - Use API, e.g. **http://www.omdbapi.com/<font color=\"blue\"><b>?</b></font>t=Rogue+One<font color=\"blue\"><b>&</b></font>plot=full<font color=\"blue\"><b>&</b></font>r=json<font color=\"blue\"><b>&</b></font>apikey={your api key}**, where\n",
    "        - t=Rogue+One: specify the movie title \n",
    "        - plot=full: return full plot\n",
    "        - r=json: result is in json format\n",
    "        - apikey: use your api key \n",
    "    - Note the format of URL:\n",
    "        - API endpoint: http://www.omdbapi.com/ \n",
    "        - parameters appear in the URL after the question mark (<font color=\"blue\"><b>?</b></font>) after the endpoint\n",
    "        - all parameters are concatenated by <font color=\"blue\"><b>\"&\"</b></font>  \n",
    "    - You can directly paste the above API to your browser\n",
    "    - Or issue API calls using requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 4.1. search movies by name\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "title='Rogue+One'\n",
    "\n",
    "# Search API: http://www.omdbapi.com/\n",
    "# has four parameters: title, full plot, result format, and api_key\n",
    "# For the get methods, parameters are attached to API URL after a \"?\"\n",
    "# Parameters are separated by \"&\"\n",
    "\n",
    "# to test, apply for an api key and use the key ere\n",
    "url=\"http://www.omdbapi.com/?t=\"+title+\\\n",
    "    \"&plot=full&r=json&apikey={your key here}\"\n",
    "\n",
    "# invoke the API \n",
    "r = requests.get(url)\n",
    "\n",
    "# Another way to pass parameters\n",
    "# payload = {'t': title, 'plot': 'full', 'apikey':\"your key here\"}\n",
    "# r=requests.get('http://www.omdbapi.com/', params=payload)\n",
    "# in case authentication is needed, use\n",
    "# r = requests.get('https://api.github.com/user', \n",
    "# auth=('user', 'pass'))\n",
    "\n",
    "# if the API call returns a successful response\n",
    "if r.status_code==200:\n",
    "    \n",
    "    # This API call returns a json object\n",
    "    # r.json() gives the json object\n",
    "    print (json.dumps(r.json(), indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
