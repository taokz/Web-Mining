{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Sentiment Mining </center>\n",
    "\n",
    "References:\n",
    "* http://spark-public.s3.amazonaws.com/nlp/slides/sentiment.pptx\n",
    "* https://www.cs.uic.edu/~liub/FBS/Sentiment-Analysis-tutorial-AAAI-2011.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Sentiment Mining ?\n",
    "* Computational study of opinions, sentiments, subjectivity, evaluations, attitudes, appraisal, affects, views, emotions, etc., expressed in text, e.g.\n",
    "  - Reviews, blogs, discussions, news, comments,   feedback, or any other documents\n",
    "  - See some interesting examples from Liu's AAAI-2011 tutorial (pp 31-38)\n",
    "<img src=\"what_is_sentiment_mining.png\" width='70%'>\n",
    "<img src=\"what_is_sentiment_mining2.png\" width='70%'>\n",
    "source: http://spark-public.s3.amazonaws.com/nlp/slides/sentiment.pptx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. A related concept: emotion\n",
    "- Based on (Parrott, 2001), people have six main emotions, **love**, **joy**, **surprise**, **anger**, **sadness**, and **fear**.  \n",
    "- Strengths of opinions/sentiments are related to certain emotions, e.g., joy, anger.  \n",
    "- However, the concepts of emotions and opinions are not equivalent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why sentiment mining\n",
    "* Our perceptions and beliefs are influnced by others\n",
    "* Whenever we make decisions, we seek out others' opinion\n",
    "    * Movie:  is this review positive or negative?\n",
    "    * Products: what do people think about the new iPhone?\n",
    "    * Public sentiment: how is consumer confidence? Is despair increasing?\n",
    "    * Politics: what do people think about this candidate or issue?\n",
    "    * Prediction: predict election outcomes or market trends from sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Objectives of Sentiment Mining\n",
    "* Example (from Liu's AAAI-2011 tutorial): \n",
    "  -  ID: <font color=\"purple\"><b>Abc123<b></font> on <font color=\"orange\"><b>5-1-2008</b></font> \"I bought an <font color=\"red\"><b>iPhone</b></font> a few days ago. It is such a <font color=\"green\"><b>nice phone</b></font>. The <font color=\"blue\"><b>touch screen</b></font> is really <font color=\"green\"><b>cool</b></font>. The <font color=\"blue\"><b>voice quality</b></font> is <font color=\"green\"><b>clear<b></font> too. It is much better than my old <font color=\"red\"><b>Blackberry</b></font>, which was a <font color=\"green\"><b>terrible phone</b></font> and so <font color=\"green\"><b>difficult to type</b></font> with its <font color=\"blue\"><b>tiny keys</b></font>. However, <font color=\"purple\"><b>my mother</b></font> was mad with me as I did not tell her before I bought the phone. She also thought the phone was too <font color=\"blue\"><b>expensive</b></font>, …”  \n",
    "* Elements of sentiment:\n",
    "  * target entity: <font color=\"red\"><b>iPhone</b></font>, <font color=\"red\"><b>Blackberry</b></font>\n",
    "  * Target **aspect/feature** of attitude: \n",
    "    - iphone: <font color=\"blue\"><b>touch screen</b></font>, <font color=\"blue\"><b>voice quality</b></font>, <font color=\"blue\"><b>expensive (price) </b></font>\n",
    "    - Blackberry: <font color=\"blue\"><b>tiny keys</b></font>\n",
    "  * Type of attitude\n",
    "    * **positive** or **negative**: <font color=\"green\"><b>nice phone</b></font>, <font color=\"green\"><b>terrible phone</b></font>\n",
    "    * **Scale of the attitute**, e.g. [1, 5], [strongly agree, agree, neutral, disagree, strongly disagree]\n",
    "  * Opinion holder: <font color=\"purple\"><b>Abc123<b></font>, <font color=\"purple\"><b>my mother</b></font>\n",
    "  * Time when the opinion is expressed: <font color=\"orange\"><b>5-1-2008</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment analysis tasks \n",
    "Giving a set of text (reviews, documents etc.):\n",
    "1. Identify objects of the sentiment analysis\n",
    "    * **Named entities**: company names, brands, proper names, hashtags etc\n",
    "    * Usually object names or synonyms are explicitly mentioned \n",
    "2. For each object, identify and extract object aspects/features that have been commented on in each review text\n",
    "    * **Explicit** features\n",
    "      * e.g. the **battery life** of this camera is too short\n",
    "    * **Implicit** features \n",
    "      * e.g. the camera is too large (implicit feature: **size**)\n",
    "3. Determine whether the sentiment on the features are positive, negative or neutral.\n",
    "4. Identify opinion holder (who) and time\n",
    "4. Generate a summary of sentiment by multidimension: \n",
    "    - on each feature and on each object \n",
    "    - by opinion holder group and time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Aspect/feature detection\n",
    "* **Explicit features/aspects**: typically can be extracted by keywords and synonyms\n",
    "  - Question: how to find synonyms?\n",
    "    - Lexical similarity based on WordNet (http://www.nltk.org/howto/wordnet.html) \n",
    "    - Word vectors\n",
    "  - Challenge: it may be difficult to find an exhaustive list of synonyms for an aspect\n",
    "  - e.g. <img src=\"hotel_feature.png\" width='50%'> Source: Lappas, T., Sabnis, G., & Valkanas, G. (2016). The <a href=https://www.researchgate.net/publication/309875086_The_Impact_of_Fake_Reviews_on_Online_Visibility_A_Vulnerability_Assessment_of_the_Hotel_Industry> impact of fake reviews on online visibility: A vulnerability assessment of the hotel industry</a>. Information Systems Research, 27(4), 940-961.  \n",
    "  \n",
    "* However, **implicit features**: may need a **supervised approach** (e.g. the camera is too large)\n",
    "  - Naive bayes, SVM, CNN with word embedding are perhaps good approaches here\n",
    "    - single-label or multi-label classification?\n",
    "  - Process:\n",
    "    - Select a set of documents with features/aspects both explicitly/implicitly mentioned\n",
    "    - Label each of the documents with features/aspects as classes\n",
    "    - Train a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 4.1.1\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from nltk.corpus import wordnet as wn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get synsets: a collection of synonymous words\n",
    "wn.synsets('motorcar')\n",
    "\n",
    "# note motorcar has just one possible context. \n",
    "# It is identified by car.n.01\n",
    "# the 1st noun (letter n) sense of car\n",
    "# \"car\" has different synonyms depending on context\n",
    "\n",
    "# Show all synonyms under sysnset car.n.1\n",
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in wn.synsets('car'):\n",
    "    print(\"\\tSynset: {}\".format(synset.name()))\n",
    "    print(\"\\tDefinition: {}\".format(synset.definition()))\n",
    "    print(\"\\tSynoymns: {}\\n\".format(synset.lemma_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Sentiment Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Challenges of sentiment analysis\n",
    "* Negation: \n",
    "  * e.g., This film should be <font color='blue'>brilliant</font>.  It sounds like a <font color='blue'>great</font> plot, the actors are <font color='blue'>first grade</font>, and the supporting cast is <font color='blue'>good</font> as well, and Stallone is attempting to deliver a good performance. However, it <font color='red'>can’t hold up</font>.\n",
    "* Sarcasm and language subtlety: sarcastic sentences are very common in political blogs, comments and discussions\n",
    "  * e.g. This is the kind of movie you go because the theater has air-conditioning\n",
    "  * e.g. What a great car, it stopped working in the second day \n",
    "  * e.g. The top of the picture was much brighter than the bottom \n",
    "* Domain Dependency\n",
    "  * e.g. unpredictable movie vs. unpredictable steering (car domain)\n",
    "* Lots of emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Unsupervised Sentiment Analysis \n",
    "* Lexicon-based method where sentiment is determined based on **opinion words** (e.g. “amazing”, “great”, “poor”) counted near features/aspects. \n",
    "    - Some useful rules:\n",
    "      - **Negative** sentiment:\n",
    "        - negative words not preceded by a negation within $n$ (e.g. three) words in the same sentence. \n",
    "        - positive words preceded by a negation within $n$ (e.g. three) words in the same sentence.\n",
    "      - **Positive** sentiment (in the similar fashion):\n",
    "        - positive words not preceded by a negation within $n$ (e.g. three) words in the same sentence. \n",
    "        - negative terms following a negation within $n$ (e.g. three) words in the same sentence\n",
    "* **Polarity**-based (Postive or Negative) approaches:\n",
    "    - <a href=\"https://www3.nd.edu/~mcdonald/Word_Lists.html\"> WordStat sentiment Dictionary</a>: This is probably one of the largest lexicons freely available. It contains ~14.000 words ( 9164 negative and 4847 positive words ) and gives words a binary classification (positive or a negative ) score.\n",
    "    - <a href=\"http://sentiwordnet.isti.cnr.it\"> SentiWordNet</a>; gives the words a positive or negative score between 0 and 1. It contains about 117.660 words, however only ~29.000 of these words have been scored (either positive or negative).\n",
    "    - LIWC (Linguistic Inquiry and Word Count)(http://www.liwc.net/)\n",
    "    - Turney Algorithm (<a href=\"https://arxiv.org/abs/cs/0212032\"> Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews</a>)\n",
    "      1. extract phrases, \n",
    "      2. detect sentiment of phrases\n",
    "         - Use search engine queries to check with cooccurrence of a phrase (e.g. low fees) with \"excellence\"/\"poor\" (Pointwise Mutual Inforamtion)\n",
    "      3. and average the sentiments\n",
    "* **Valence**-based where the **intensity** of the sentiment is considered, e.g. excellent, good, average\n",
    "     - VADER: <a href=\"http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf\"> A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. VADER \n",
    "- The method of VADER:\n",
    "    1. Created lexicons of sentiment-related words (~9000)\n",
    "      -  Built based on existing well-established sentiment word-banks (e.g. LIWC). \n",
    "      - Incorporated many lexical features \n",
    "        - Western-style emoticons10 (for example, \":-\")\n",
    "        - Sentiment-related acronyms (e.g., LOL) and  commonly used slangs with sentiment value (e.g., \"nah\", \"meh\" and \"giggly\"). \n",
    "    2. Rated sentiment-related words were manually rated in terms of sentiment intensity through Amazon Mechancical Turk: positive or negative (and optionally, to what degree)\n",
    "    3. Implemented heurestics rules:\n",
    "        - **Punctuation exclamation mark(!)** increases sentiment intensity, e.g. *\"The food here is good!!!\"*\n",
    "        - **Capitalization, specifically ALL-CAPS** of a sentiment-relevant word increases the sentiment intensity, e.g. *\"The food here is GREAT!\"*\n",
    "        - **Degree modifiers** (also called intensifiers, e.g. extremely) increases intensity\n",
    "        - **Contrastive conjunction \"but\"** signals a shift in sentiment polarity, with the sentiment of the text following the conjunction being dominant. e.g. *\"The food here is great, but the service is horrible\"*. \n",
    "\n",
    "- VADER analyzes a piece of text to see if any of the words in the text is present in the lexicon. Sentiment metrics are derived from the ratings of such words\n",
    "    - **Positive**, **neutral** and **negative**, represent the proportion of the text that falls into those categories. \n",
    "    - The final metric, the compound score, is the sum of all of the lexicon ratings which have been standardized to range between -1 and 1 based on some heuristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.2.3.1 SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "text='The food is so good and the atmosphere is nice'\n",
    "ss = sid.polarity_scores(text)\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.2.3.2 Easy sentences\n",
    "\n",
    "#http://www.nltk.org/howto/sentiment.html\n",
    "#http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html\n",
    "#https://www.researchgate.net/publication/275828927_VADER_A_Parsimonious_Rule-based_Model_for_Sentiment_Analysis_of_Social_Media_Text\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "sentences = [\"VADER is smart, handsome, and funny.\", # positive sentence example\n",
    " \"VADER is smart, handsome, and funny!\", # punctuation emphasis handled correctly (sentiment intensity adjusted)\n",
    " \"VADER is very smart, handsome, and funny.\",  # booster words handled correctly (sentiment intensity adjusted)\n",
    " \"VADER is VERY SMART, handsome, and FUNNY.\",  # emphasis for ALLCAPS handled\n",
    " \"VADER is VERY SMART, handsome, and FUNNY!!!\",# combination of signals - VADER appropriately adjusts intensity\n",
    " \"VADER is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!\",# booster words & punctuation make this close to ceiling for score\n",
    " \"The book was good.\",         # positive sentence\n",
    " \"The book was kind of good.\", # qualified positive sentence is handled correctly (intensity adjusted)\n",
    " \"The plot was good, but the characters \\\n",
    " are uncompelling and the dialog is not great.\", # mixed negation sentence\n",
    " \"A really bad, horrible book.\",       # negative sentence with booster words\n",
    " \"At least it isn't a horrible book.\", # negated negative sentence with contraction\n",
    " \":) and :D\"     # emoticons handled\n",
    " ]\n",
    "\n",
    "# initalize analyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.2.3.3. Tricky sentences\n",
    "# How do you think the performance of VADER\n",
    "# for this group of sentences?\n",
    "\n",
    "tricky_sentences = [\n",
    "    \"Sentiment analysis has never been good.\",\n",
    "    \"Sentiment analysis with VADER has never been this good.\",\n",
    "    \"Warren Beatty has never been so entertaining.\",\n",
    "    \"I won't say that the movie is astounding and I wouldn't claim that \"]\n",
    "\n",
    "# initalize analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sentence in tricky_sentences:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.2.3.4. Tricky Paragraph\n",
    "\n",
    "# Deal with Paragraph\n",
    "# question: if a paragraph contains mixed positive and \n",
    "# negative sentences, how do you determine the sentiment\n",
    "# of the entire paragraph?\n",
    "\n",
    "paragraph = \"This film should be brilliant. \\\n",
    "             It sounds like a great plot, the actors are first grade, \\\n",
    "             and the supporting cast is good as well, \\\n",
    "             and Stallone is attempting to deliver a good performance. \\\n",
    "             However, it can’t hold up.\"\n",
    "\n",
    "# split into sentences\n",
    "lines_list = tokenize.sent_tokenize(paragraph)\n",
    "\n",
    "# initalize analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# analyze the sentiment sentence by sentence\n",
    "\n",
    "for sentence in lines_list:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# what if you analyze the entire sentence \\\n",
    "# as a whole?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 4.5. Design a document sentiment classifier based on VADER\n",
    "# test your classifier using amazon review dataset\n",
    "# and estimate its accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Supervised Sentiment Analysis\n",
    "- Naive Bayes (Base line), SVM, CNN. \n",
    "- Different ways to generate feature space:\n",
    "  * TF-IDF with all tokens\n",
    "  * with binary counts only\n",
    "  * Word embedding\n",
    "- Check lecture notes for \"Text Classification\" and \"Deep Learning II\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
