{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Deep Learning and Text Analytics II</center>\n",
    "\n",
    "References:\n",
    "- General introduction\n",
    "   - http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/\n",
    "- Word vector:\n",
    "     - https://code.google.com/archive/p/word2vec/\n",
    "- Keras tutorial\n",
    "     - https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "- CNN\n",
    "     - http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Agenda\n",
    "- Introduction to neural networks\n",
    "- Word/Document Vectors (vector representation of words/phrases/paragraphs)\n",
    "- Convolutional neural network (CNN)\n",
    "- Application of CNN in text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word2Vector (a.k.a word embedding) and Doc2Vector\n",
    "\n",
    "### 4.1. Word2Vector\n",
    " - Vector representation of words (i.e. word vectors) learned using neural network\n",
    "   - e.g. \"apple\" : [0.35, -0.2, 0.4, ...], 'mongo':  [0.32, -0.18, 0.5, ...]\n",
    "   - Interesting properties of word vectors:\n",
    "    * **Words with similar semantics have close word vectors**\n",
    "    * **Composition**: e.g. vector(\"woman\")+vector(\"king\")-vector('man') $\\approx$ vector(\"queen\")\n",
    " - Models:\n",
    "   - **CBOW** (Continuous Bag of Words): Predict a target word based on context\n",
    "     - e.g. the fox jumped over the lazy dog\n",
    "     - Assuming symmetric context with window size 3, this sentence can create training samples: \n",
    "       - ([-, fox], the) \n",
    "       - ([the, jumped], fox) \n",
    "       - ([fox, over], jumped)\n",
    "       - ([jumped, the], over) \n",
    "       - ...\n",
    "       \n",
    "       <img src=\"cbow.png\" width=\"50%\">\n",
    "       source: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "   - **Skip Gram**: predict context based on target words\n",
    "   \n",
    "        <img src=\"skip_gram.png\" width=\"50%\">\n",
    "        source: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "   - Nagtive Sampling: \n",
    "       - When training a neural network, for each sample,  all weights are adjusted slightly so that it predicts that training sample more accurately. \n",
    "       - CBOW or skip gram models have tremendous number of weights, all of which would be updated slightly by every one of billions of training samples!\n",
    "       - Negative sampling addresses this by having **each training sample only modify a small percentage of the weights, rather than all of them**. \n",
    "       - e.g. when training with sample ([fox, over], jumped), update output weights connected to \"jumped\" along with a small number of other \"negative words\" sampled randomly\n",
    "       - For details, check http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up interactive shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a little longer and more detailed than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Only Michelle Branch save this album!!!!All gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A surprisingly good book, given its inherently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a wonderful, quiet and relaxing CD tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The lights that I received are absolutely not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      2  This is a little longer and more detailed than...\n",
       "1      1  Only Michelle Branch save this album!!!!All gu...\n",
       "2      2  A surprisingly good book, given its inherently...\n",
       "3      2  This is a wonderful, quiet and relaxing CD tha...\n",
       "4      1  The lights that I received are absolutely not ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'little', 'longer', 'and', 'more', 'detailed', 'than', 'the', 'first', 'two', 'books', 'in', 'the', 'series', 'however', 'have', 'enjoyed', 'each', 'new', 'aspect', 'of', 'the', 'exciting', 'fantasy', 'universe'], ['only', 'michelle', 'branch', 'save', 'this', 'album', 'all', 'guys', 'play', 'along', 'with', 'unenthusiastic', 'beat', 'even', 'karl']]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4.1.1 Train your word vector\n",
    "\n",
    "import pandas as pd\n",
    "import nltk,string\n",
    "\n",
    "# Load data\n",
    "data=pd.read_csv('../amazon_review_large.csv', header=None)\n",
    "data.columns=['label','text']\n",
    "data.head()\n",
    "\n",
    "# tokenize each document into a list of unigrams\n",
    "# strip punctuations and leading/trailing spaces from unigrams\n",
    "# only unigrams with 2 or more characters are taken\n",
    "sentences=[ [token.strip(string.punctuation).strip() \\\n",
    "             for token in nltk.word_tokenize(doc.lower()) \\\n",
    "                 if token not in string.punctuation and \\\n",
    "                 len(token.strip(string.punctuation).strip())>=2]\\\n",
    "             for doc in data[\"text\"]]\n",
    "print(sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2018-11-29 16:07:06,077 : INFO : collecting all words and their counts\n",
      "2018-11-29 16:07:06,078 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-11-29 16:07:06,297 : INFO : PROGRESS: at sentence #10000, processed 712003 words, keeping 36988 word types\n",
      "2018-11-29 16:07:06,580 : INFO : collected 55278 word types from a corpus of 1424321 raw words and 20000 sentences\n",
      "2018-11-29 16:07:06,580 : INFO : Loading a fresh vocabulary\n",
      "2018-11-29 16:07:06,647 : INFO : effective_min_count=5 retains 12133 unique words (21% of original 55278, drops 43145)\n",
      "2018-11-29 16:07:06,647 : INFO : effective_min_count=5 leaves 1361983 word corpus (95% of original 1424321, drops 62338)\n",
      "2018-11-29 16:07:06,714 : INFO : deleting the raw counts dictionary of 55278 items\n",
      "2018-11-29 16:07:06,714 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2018-11-29 16:07:06,714 : INFO : downsampling leaves estimated 1015574 word corpus (74.6% of prior 1361983)\n",
      "2018-11-29 16:07:06,780 : INFO : estimated required memory for 12133 words and 200 dimensions: 25479300 bytes\n",
      "2018-11-29 16:07:06,780 : INFO : resetting layer weights\n",
      "2018-11-29 16:07:07,097 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:07:08,115 : INFO : EPOCH 1 - PROGRESS: at 75.65% examples, 755354 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:07:08,398 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:07:08,415 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:07:08,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:07:08,419 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:07:08,419 : INFO : EPOCH - 1 : training on 1424321 raw words (1015781 effective words) took 1.3s, 772304 effective words/s\n",
      "2018-11-29 16:07:09,416 : INFO : EPOCH 2 - PROGRESS: at 77.00% examples, 781157 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:07:09,699 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:07:09,700 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:07:09,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:07:09,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:07:09,717 : INFO : EPOCH - 2 : training on 1424321 raw words (1015907 effective words) took 1.3s, 786170 effective words/s\n",
      "2018-11-29 16:07:10,718 : INFO : EPOCH 3 - PROGRESS: at 74.19% examples, 752447 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:07:11,034 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:07:11,039 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:07:11,050 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:07:11,050 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:07:11,062 : INFO : EPOCH - 3 : training on 1424321 raw words (1016332 effective words) took 1.3s, 761978 effective words/s\n",
      "2018-11-29 16:07:12,069 : INFO : EPOCH 4 - PROGRESS: at 75.65% examples, 765697 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:07:12,357 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:07:12,362 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:07:12,367 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:07:12,375 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:07:12,375 : INFO : EPOCH - 4 : training on 1424321 raw words (1015448 effective words) took 1.3s, 773093 effective words/s\n",
      "2018-11-29 16:07:13,396 : INFO : EPOCH 5 - PROGRESS: at 76.35% examples, 766823 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:07:13,670 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:07:13,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:07:13,687 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:07:13,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:07:13,693 : INFO : EPOCH - 5 : training on 1424321 raw words (1015449 effective words) took 1.3s, 776998 effective words/s\n",
      "2018-11-29 16:07:13,694 : INFO : training on a 7121605 raw words (5078917 effective words) took 6.6s, 770080 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# Train your own word vectors using gensim\n",
    "\n",
    "# gensim.models is the package for word2vec\n",
    "# check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "# for detailed description\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# print out tracking information\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \\\n",
    "                    level=logging.INFO)\n",
    "\n",
    "# min_count: words with total frequency lower than this are ignored\n",
    "# size: the dimension of word vector\n",
    "# window: context window, i.e. the maximum distance \n",
    "#         between the current and predicted word \n",
    "#         within a sentence (i.e. the length of ngrams)\n",
    "# workers: # of parallel threads in training\n",
    "# for other parameters, check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "wv_model = word2vec.Word2Vec(sentences, \\\n",
    "            min_count=5, size=200, \\\n",
    "            window=5, workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 16:10:06,045 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K:\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('metal', 0.768135666847229),\n",
       " ('sounds', 0.7587062120437622),\n",
       " ('vocals', 0.750717282295227),\n",
       " ('production', 0.74760901927948),\n",
       " ('rock', 0.7452607154846191)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound' but not relevant to 'film'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rock', 0.8133113980293274),\n",
       " ('pop', 0.7807926535606384),\n",
       " ('lyrics', 0.7637144923210144),\n",
       " ('beats', 0.754810094833374),\n",
       " ('dance', 0.7345940470695496)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'film':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9219632"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'city':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009261133"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word does not match with others in the list of ['sound', 'music', 'graphics', 'actor', 'book']:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'book'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector for 'movie':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.77269727, -1.4913762 , -1.0019791 , -1.2563334 , -0.12225643,\n",
       "       -1.416501  ,  1.2577945 , -0.5184871 ,  0.6585174 , -0.14731687,\n",
       "        0.52918917,  0.30294475,  0.495267  ,  0.21776067,  0.124472  ,\n",
       "       -1.5360495 ,  0.54938453, -0.06506   , -1.639378  , -0.24853028,\n",
       "        0.7968809 , -1.2775854 ,  0.13571614, -0.5208313 ,  1.0953196 ,\n",
       "       -0.3756403 , -1.5401527 , -1.8848073 , -0.9565676 , -0.81631154,\n",
       "       -1.5816301 ,  0.8726593 , -1.9249322 , -0.27146304, -0.7126626 ,\n",
       "        0.08017053, -1.3893516 ,  0.57443464,  1.6364825 , -1.101771  ,\n",
       "       -0.86638355,  1.5470277 ,  2.1122425 , -0.57389414, -0.06188415,\n",
       "       -0.53467387,  0.7612246 ,  0.25090617, -1.0429192 ,  0.80020404,\n",
       "       -0.3509972 ,  1.3647641 ,  1.1475662 ,  0.23796152, -0.5293686 ,\n",
       "       -0.89735174, -1.1483487 , -0.8870737 , -0.18562146,  1.0308938 ,\n",
       "       -0.60114026, -0.04594025, -0.421823  ,  1.1857368 , -0.17878392,\n",
       "        1.1128901 , -0.68922096,  0.6759488 , -0.18189444,  0.67669547,\n",
       "       -0.8112388 , -0.25658923, -0.7070955 ,  1.9360776 ,  0.6065412 ,\n",
       "       -0.47972393,  0.12294027, -0.7938716 ,  0.25211293,  1.6146445 ,\n",
       "       -0.36999384,  1.049893  ,  0.9078559 , -0.96461385, -0.08960876,\n",
       "        0.28435275,  0.21821049, -0.60550094, -1.1043705 , -0.69786704,\n",
       "        0.12554732, -0.17100833, -0.5390522 ,  0.4112648 , -1.0845039 ,\n",
       "       -0.7979792 , -0.7767074 , -0.84314156, -0.73648334, -0.55995196,\n",
       "       -0.15940396, -0.8344762 , -0.5995809 ,  0.6405307 ,  0.8661147 ,\n",
       "        1.2650728 ,  1.0515083 ,  1.1747751 , -0.86632186,  0.2893218 ,\n",
       "        0.811377  ,  0.0248031 , -0.42074353,  0.5006709 , -0.29576305,\n",
       "        1.021841  ,  0.1292443 , -0.6084993 ,  0.7691396 ,  2.0140598 ,\n",
       "        1.3324313 , -0.43976343,  1.006003  , -0.61457616, -0.08943936,\n",
       "       -1.0992777 , -0.1202696 , -0.4609794 ,  1.1047179 ,  1.5530722 ,\n",
       "       -0.7465321 , -0.06136184,  1.2173063 ,  0.23307942, -0.10070151,\n",
       "       -0.26136082,  0.04527347, -1.2641342 , -0.60950065, -1.0814624 ,\n",
       "       -0.10867208,  0.43442667, -0.67189324,  0.25454292, -0.7316441 ,\n",
       "        0.98224014, -1.6306415 ,  0.5608005 , -2.6959975 ,  0.7261172 ,\n",
       "       -0.22851428, -1.3218769 ,  0.7656932 ,  0.35884294, -2.6852696 ,\n",
       "       -2.2272573 , -1.9857117 ,  0.38042858,  0.10453428, -0.5117533 ,\n",
       "        0.2084281 ,  1.4015547 , -0.4756179 , -1.7352483 ,  1.7819141 ,\n",
       "       -0.87290806,  2.3525958 , -0.08849494, -0.09644988,  0.7801178 ,\n",
       "       -0.08978796,  1.0549197 ,  0.37884194,  0.9858719 ,  0.56210744,\n",
       "        0.55840576, -2.2890987 , -0.01303246, -2.1224585 , -0.24679804,\n",
       "        0.9193536 ,  0.29488608,  0.74678534, -1.4522054 , -0.389866  ,\n",
       "        0.5850467 , -0.13796376,  0.73560596,  2.106198  , -0.8934329 ,\n",
       "        1.3348032 ,  0.06800973,  0.8989442 ,  0.704554  , -0.7052827 ,\n",
       "        0.4381336 , -2.3445568 ,  2.4431107 ,  0.45042893,  0.47325042],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test word2vec model\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound'\")\n",
    "wv_model.wv.most_similar('sound', topn=5)\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound' but not relevant to 'film'\")\n",
    "wv_model.wv.most_similar(positive=['sound','music'], \\\n",
    "                         negative=['film'], topn=5)\n",
    "\n",
    "print(\"Similarity between 'movie' and 'film':\")\n",
    "wv_model.wv.similarity('movie','film') \n",
    "\n",
    "print(\"Similarity between 'movie' and 'city':\")\n",
    "wv_model.wv.similarity('movie','city') \n",
    "\n",
    "print(\"Word does not match with others in the list of \\\n",
    "['sound', 'music', 'graphics', 'actor', 'book']:\")\n",
    "wv_model.wv.doesnt_match([\"sound\", \"music\", \\\n",
    "                          \"graphics\", \"actor\", \"book\"])\n",
    "\n",
    "print(\"Word vector for 'movie':\")\n",
    "wv_model.wv['movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Pretrained Word Vectors\n",
    "- Google published pre-trained 300-dimensional vectors for 3 million words and phrases that were trained on Google News dataset (about 100 billion words)(https://code.google.com/archive/p/word2vec/)\n",
    "- GloVe (Global Vectors for Word Representation): Pretained word vectors from different data sources provided by Standford https://nlp.stanford.edu/projects/glove/\n",
    "- FastText by Facebook https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 16:10:22,879 : INFO : loading projection weights from GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-58510fb79360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m model.wv.most_similar(positive=['women','king'], \\\n",
      "\u001b[1;32mK:\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[0;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1438\u001b[1;33m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mK:\\Anaconda3\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mK:\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[1;34m(uri, mode, **kw)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mode should be a string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m     \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shortcut_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mK:\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, **kw)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "# Exercise 4.2.1: Use pretrained word vectors\n",
    "\n",
    "# download the bin file for pretrained word vectors\n",
    "# from above links, e.g. https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "# Warning: the bin file is very big (over 2G)\n",
    "# You need a powerful machine to load it\n",
    "\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.KeyedVectors.\\\n",
    "load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) \n",
    "\n",
    "model.wv.most_similar(positive=['women','king'], \\\n",
    "                      negative='man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Sentence/Paragraph/Document Vectors\n",
    "- So far we learned vector representation of words\n",
    "- A lot of times, our samples are sentences, paragraphs, or documents\n",
    "- How to create vector representations of sentences, paragraphs, or documents?\n",
    "  - Weighted average of word vectors (however, word order is lost as \"bag of words\")\n",
    "  - Concatenation of word vectors (large space)\n",
    "  - ??\n",
    "- Paragraph Vector: A distributed memory model (PV-DM)\n",
    "   - Word vectors are shared across paragraphs\n",
    "   - The paragraph vector is shared across all contexts generated from the same paragraph but not across paragraphs\n",
    "   - **Both pragraph vectors and word vectors** are returned\n",
    "   - Paragraph vectors can be used for document retrival or as features for classification or clustering\n",
    "  <img src=\"doc2vec.png\" width=\"50%\">\n",
    "   Source: Le Q. and Mikolov, T. Distributed Representations of Sentences and Documents https://arxiv.org/pdf/1405.4053v2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['this', 'is', 'little', 'longer', 'and', 'more', 'detailed', 'than', 'the', 'first', 'two', 'books', 'in', 'the', 'series', 'however', 'have', 'enjoyed', 'each', 'new', 'aspect', 'of', 'the', 'exciting', 'fantasy', 'universe'], tags=['0'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 4.3.1 Train your word vector\n",
    "\n",
    "# We have tokenized sentences\n",
    "# Label each sentence with a unique tag\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "docs=[TaggedDocument(sentences[i], [str(i)]) for i in range(len(sentences)) ]\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K:\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "2018-11-29 16:46:03,112 : INFO : collecting all words and their counts\n",
      "2018-11-29 16:46:03,113 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-11-29 16:46:03,372 : INFO : PROGRESS: at example #10000, processed 712003 words (2667276/s), 36988 word types, 10000 tags\n",
      "2018-11-29 16:46:03,756 : INFO : collected 55278 word types and 20000 unique tags from a corpus of 20000 examples and 1424321 words\n",
      "2018-11-29 16:46:03,756 : INFO : Loading a fresh vocabulary\n",
      "2018-11-29 16:46:03,821 : INFO : effective_min_count=5 retains 12133 unique words (21% of original 55278, drops 43145)\n",
      "2018-11-29 16:46:03,821 : INFO : effective_min_count=5 leaves 1361983 word corpus (95% of original 1424321, drops 62338)\n",
      "2018-11-29 16:46:03,889 : INFO : deleting the raw counts dictionary of 55278 items\n",
      "2018-11-29 16:46:03,889 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2018-11-29 16:46:03,899 : INFO : downsampling leaves estimated 1015574 word corpus (74.6% of prior 1361983)\n",
      "2018-11-29 16:46:03,973 : INFO : estimated required memory for 12133 words and 200 dimensions: 45479300 bytes\n",
      "2018-11-29 16:46:03,973 : INFO : resetting layer weights\n",
      "2018-11-29 16:46:04,884 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:05,891 : INFO : EPOCH 1 - PROGRESS: at 32.68% examples, 339614 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:06,895 : INFO : EPOCH 1 - PROGRESS: at 66.92% examples, 345566 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:07,818 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:07,829 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:07,838 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:07,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:07,852 : INFO : EPOCH - 1 : training on 1424321 raw words (1035277 effective words) took 3.0s, 349514 effective words/s\n",
      "2018-11-29 16:46:07,852 : INFO : training on a 1424321 raw words (1035277 effective words) took 3.0s, 348820 effective words/s\n",
      "2018-11-29 16:46:07,880 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:07,881 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:08,927 : INFO : EPOCH 1 - PROGRESS: at 20.11% examples, 201208 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:10,002 : INFO : EPOCH 1 - PROGRESS: at 39.91% examples, 194851 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:11,014 : INFO : EPOCH 1 - PROGRESS: at 59.30% examples, 196446 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:12,049 : INFO : EPOCH 1 - PROGRESS: at 76.79% examples, 190762 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:13,150 : INFO : EPOCH 1 - PROGRESS: at 96.40% examples, 189787 words/s, in_qsize 6, out_qsize 0\n",
      "2018-11-29 16:46:13,191 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:13,204 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:13,270 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:13,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:13,289 : INFO : EPOCH - 1 : training on 1424321 raw words (1036023 effective words) took 5.4s, 191791 effective words/s\n",
      "2018-11-29 16:46:13,293 : INFO : training on a 1424321 raw words (1036023 effective words) took 5.4s, 191498 effective words/s\n",
      "2018-11-29 16:46:13,369 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:13,369 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:14,414 : INFO : EPOCH 1 - PROGRESS: at 25.91% examples, 262047 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:15,435 : INFO : EPOCH 1 - PROGRESS: at 54.13% examples, 271710 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:16,451 : INFO : EPOCH 1 - PROGRESS: at 81.33% examples, 274562 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:16,954 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:16,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:16,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:16,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:16,991 : INFO : EPOCH - 1 : training on 1424321 raw words (1035647 effective words) took 3.6s, 287736 effective words/s\n",
      "2018-11-29 16:46:16,992 : INFO : training on a 1424321 raw words (1035647 effective words) took 3.6s, 286349 effective words/s\n",
      "2018-11-29 16:46:17,013 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:17,017 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:18,054 : INFO : EPOCH 1 - PROGRESS: at 28.88% examples, 285427 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:19,075 : INFO : EPOCH 1 - PROGRESS: at 60.77% examples, 307329 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:20,083 : INFO : EPOCH 1 - PROGRESS: at 92.33% examples, 312405 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:20,261 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:20,283 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:20,288 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:20,293 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:20,295 : INFO : EPOCH - 1 : training on 1424321 raw words (1035799 effective words) took 3.3s, 316647 effective words/s\n",
      "2018-11-29 16:46:20,296 : INFO : training on a 1424321 raw words (1035799 effective words) took 3.3s, 315921 effective words/s\n",
      "2018-11-29 16:46:20,322 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:20,323 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:21,342 : INFO : EPOCH 1 - PROGRESS: at 19.86% examples, 199000 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:22,392 : INFO : EPOCH 1 - PROGRESS: at 39.82% examples, 199139 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:23,427 : INFO : EPOCH 1 - PROGRESS: at 64.98% examples, 216861 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:24,480 : INFO : EPOCH 1 - PROGRESS: at 93.61% examples, 233645 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:24,629 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:24,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:24,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:24,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:24,669 : INFO : EPOCH - 1 : training on 1424321 raw words (1035349 effective words) took 4.3s, 238777 effective words/s\n",
      "2018-11-29 16:46:24,670 : INFO : training on a 1424321 raw words (1035349 effective words) took 4.3s, 238230 effective words/s\n",
      "2018-11-29 16:46:24,706 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:24,707 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:25,712 : INFO : EPOCH 1 - PROGRESS: at 18.27% examples, 188448 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:26,739 : INFO : EPOCH 1 - PROGRESS: at 43.38% examples, 222159 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:27,749 : INFO : EPOCH 1 - PROGRESS: at 72.67% examples, 247878 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 16:46:28,615 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:28,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:28,629 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:28,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:28,642 : INFO : EPOCH - 1 : training on 1424321 raw words (1035937 effective words) took 3.9s, 264299 effective words/s\n",
      "2018-11-29 16:46:28,643 : INFO : training on a 1424321 raw words (1035937 effective words) took 3.9s, 263277 effective words/s\n",
      "2018-11-29 16:46:28,665 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:28,665 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:29,683 : INFO : EPOCH 1 - PROGRESS: at 30.60% examples, 316154 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:30,687 : INFO : EPOCH 1 - PROGRESS: at 63.44% examples, 327416 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:31,696 : INFO : EPOCH 1 - PROGRESS: at 97.95% examples, 335950 words/s, in_qsize 3, out_qsize 1\n",
      "2018-11-29 16:46:31,696 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:31,725 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:31,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:31,743 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:31,744 : INFO : EPOCH - 1 : training on 1424321 raw words (1036227 effective words) took 3.1s, 337792 effective words/s\n",
      "2018-11-29 16:46:31,744 : INFO : training on a 1424321 raw words (1036227 effective words) took 3.1s, 336876 effective words/s\n",
      "2018-11-29 16:46:31,769 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:31,770 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:32,881 : INFO : EPOCH 1 - PROGRESS: at 17.64% examples, 164477 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:33,881 : INFO : EPOCH 1 - PROGRESS: at 35.09% examples, 171859 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:34,934 : INFO : EPOCH 1 - PROGRESS: at 53.90% examples, 176704 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:35,944 : INFO : EPOCH 1 - PROGRESS: at 72.11% examples, 179086 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:36,987 : INFO : EPOCH 1 - PROGRESS: at 90.38% examples, 179224 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:37,344 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:37,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:37,414 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:37,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:37,420 : INFO : EPOCH - 1 : training on 1424321 raw words (1035492 effective words) took 5.6s, 183549 effective words/s\n",
      "2018-11-29 16:46:37,420 : INFO : training on a 1424321 raw words (1035492 effective words) took 5.6s, 183287 effective words/s\n",
      "2018-11-29 16:46:37,477 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:37,477 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:38,494 : INFO : EPOCH 1 - PROGRESS: at 27.87% examples, 288138 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:39,518 : INFO : EPOCH 1 - PROGRESS: at 57.45% examples, 292905 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:40,519 : INFO : EPOCH 1 - PROGRESS: at 86.83% examples, 296328 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:40,907 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:40,911 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:40,933 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:40,944 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:40,945 : INFO : EPOCH - 1 : training on 1424321 raw words (1035957 effective words) took 3.5s, 299744 effective words/s\n",
      "2018-11-29 16:46:40,946 : INFO : training on a 1424321 raw words (1035957 effective words) took 3.5s, 298902 effective words/s\n",
      "2018-11-29 16:46:40,981 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:40,981 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:42,081 : INFO : EPOCH 1 - PROGRESS: at 20.38% examples, 192826 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:43,107 : INFO : EPOCH 1 - PROGRESS: at 42.02% examples, 205148 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:44,117 : INFO : EPOCH 1 - PROGRESS: at 62.18% examples, 206031 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:45,161 : INFO : EPOCH 1 - PROGRESS: at 85.98% examples, 213491 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:45,592 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:45,598 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:45,607 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:45,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:45,623 : INFO : EPOCH - 1 : training on 1424321 raw words (1035597 effective words) took 4.6s, 223660 effective words/s\n",
      "2018-11-29 16:46:45,624 : INFO : training on a 1424321 raw words (1035597 effective words) took 4.6s, 223256 effective words/s\n",
      "2018-11-29 16:46:45,658 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:45,658 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:46,737 : INFO : EPOCH 1 - PROGRESS: at 20.12% examples, 198564 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:47,756 : INFO : EPOCH 1 - PROGRESS: at 42.21% examples, 208832 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:48,829 : INFO : EPOCH 1 - PROGRESS: at 62.42% examples, 204529 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:49,841 : INFO : EPOCH 1 - PROGRESS: at 81.83% examples, 203481 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:50,664 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:50,687 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:50,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:46:50,708 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:50,708 : INFO : EPOCH - 1 : training on 1424321 raw words (1035471 effective words) took 5.0s, 205884 effective words/s\n",
      "2018-11-29 16:46:50,712 : INFO : training on a 1424321 raw words (1035471 effective words) took 5.0s, 205189 effective words/s\n",
      "2018-11-29 16:46:50,760 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:50,767 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:51,807 : INFO : EPOCH 1 - PROGRESS: at 17.57% examples, 176945 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:52,843 : INFO : EPOCH 1 - PROGRESS: at 37.08% examples, 185714 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:53,916 : INFO : EPOCH 1 - PROGRESS: at 56.37% examples, 186918 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:54,992 : INFO : EPOCH 1 - PROGRESS: at 75.97% examples, 187327 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:56,037 : INFO : EPOCH 1 - PROGRESS: at 95.59% examples, 188588 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:56,140 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:46:56,183 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:46:56,190 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 16:46:56,194 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:46:56,197 : INFO : EPOCH - 1 : training on 1424321 raw words (1035689 effective words) took 5.4s, 191307 effective words/s\n",
      "2018-11-29 16:46:56,198 : INFO : training on a 1424321 raw words (1035689 effective words) took 5.4s, 190723 effective words/s\n",
      "2018-11-29 16:46:56,249 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:46:56,249 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:46:57,272 : INFO : EPOCH 1 - PROGRESS: at 16.76% examples, 171964 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:46:58,436 : INFO : EPOCH 1 - PROGRESS: at 34.19% examples, 163612 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:46:59,449 : INFO : EPOCH 1 - PROGRESS: at 52.92% examples, 172926 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:00,459 : INFO : EPOCH 1 - PROGRESS: at 70.41% examples, 174172 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:01,475 : INFO : EPOCH 1 - PROGRESS: at 88.00% examples, 175084 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:02,054 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:02,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:02,101 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:02,117 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:02,120 : INFO : EPOCH - 1 : training on 1424321 raw words (1035942 effective words) took 5.9s, 176963 effective words/s\n",
      "2018-11-29 16:47:02,122 : INFO : training on a 1424321 raw words (1035942 effective words) took 5.9s, 176529 effective words/s\n",
      "2018-11-29 16:47:02,169 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:02,170 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:03,178 : INFO : EPOCH 1 - PROGRESS: at 24.43% examples, 252488 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:04,189 : INFO : EPOCH 1 - PROGRESS: at 50.92% examples, 261566 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:05,227 : INFO : EPOCH 1 - PROGRESS: at 76.89% examples, 261295 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:06,049 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:06,062 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:06,089 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:06,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:06,102 : INFO : EPOCH - 1 : training on 1424321 raw words (1036197 effective words) took 3.9s, 264274 effective words/s\n",
      "2018-11-29 16:47:06,102 : INFO : training on a 1424321 raw words (1036197 effective words) took 3.9s, 263596 effective words/s\n",
      "2018-11-29 16:47:06,140 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:06,142 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:07,153 : INFO : EPOCH 1 - PROGRESS: at 22.88% examples, 238233 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:08,170 : INFO : EPOCH 1 - PROGRESS: at 48.09% examples, 247451 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:09,177 : INFO : EPOCH 1 - PROGRESS: at 72.45% examples, 248686 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:10,163 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:10,212 : INFO : EPOCH 1 - PROGRESS: at 98.67% examples, 251270 words/s, in_qsize 2, out_qsize 1\n",
      "2018-11-29 16:47:10,216 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:10,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:10,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:10,231 : INFO : EPOCH - 1 : training on 1424321 raw words (1034985 effective words) took 4.1s, 253636 effective words/s\n",
      "2018-11-29 16:47:10,231 : INFO : training on a 1424321 raw words (1034985 effective words) took 4.1s, 253058 effective words/s\n",
      "2018-11-29 16:47:10,263 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:10,264 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:11,318 : INFO : EPOCH 1 - PROGRESS: at 17.48% examples, 173715 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:12,440 : INFO : EPOCH 1 - PROGRESS: at 36.95% examples, 176941 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:13,461 : INFO : EPOCH 1 - PROGRESS: at 56.59% examples, 183818 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:14,500 : INFO : EPOCH 1 - PROGRESS: at 76.42% examples, 186542 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:15,518 : INFO : EPOCH 1 - PROGRESS: at 97.16% examples, 191667 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-29 16:47:15,553 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:15,603 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:15,603 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:15,624 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:15,627 : INFO : EPOCH - 1 : training on 1424321 raw words (1034675 effective words) took 5.3s, 193430 effective words/s\n",
      "2018-11-29 16:47:15,627 : INFO : training on a 1424321 raw words (1034675 effective words) took 5.4s, 192931 effective words/s\n",
      "2018-11-29 16:47:15,672 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:15,674 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:16,803 : INFO : EPOCH 1 - PROGRESS: at 20.42% examples, 188166 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:17,887 : INFO : EPOCH 1 - PROGRESS: at 42.66% examples, 200337 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:18,889 : INFO : EPOCH 1 - PROGRESS: at 64.37% examples, 207478 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:19,906 : INFO : EPOCH 1 - PROGRESS: at 84.57% examples, 206984 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:20,428 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:20,457 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:20,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:20,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:20,481 : INFO : EPOCH - 1 : training on 1424321 raw words (1035657 effective words) took 4.8s, 216081 effective words/s\n",
      "2018-11-29 16:47:20,482 : INFO : training on a 1424321 raw words (1035657 effective words) took 4.8s, 215456 effective words/s\n",
      "2018-11-29 16:47:20,508 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:20,508 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:21,541 : INFO : EPOCH 1 - PROGRESS: at 20.07% examples, 207364 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:22,575 : INFO : EPOCH 1 - PROGRESS: at 42.12% examples, 215835 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:23,582 : INFO : EPOCH 1 - PROGRESS: at 65.41% examples, 222646 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:24,595 : INFO : EPOCH 1 - PROGRESS: at 92.22% examples, 234471 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:24,812 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:24,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:24,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:24,862 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:24,865 : INFO : EPOCH - 1 : training on 1424321 raw words (1035325 effective words) took 4.3s, 238846 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 16:47:24,865 : INFO : training on a 1424321 raw words (1035325 effective words) took 4.3s, 238241 effective words/s\n",
      "2018-11-29 16:47:24,896 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:24,896 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:25,916 : INFO : EPOCH 1 - PROGRESS: at 16.21% examples, 164994 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:26,967 : INFO : EPOCH 1 - PROGRESS: at 39.67% examples, 199648 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:28,020 : INFO : EPOCH 1 - PROGRESS: at 67.48% examples, 225806 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:29,020 : INFO : EPOCH 1 - PROGRESS: at 95.69% examples, 241206 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:29,116 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:29,138 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:29,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:29,175 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:29,176 : INFO : EPOCH - 1 : training on 1424321 raw words (1035475 effective words) took 4.3s, 242835 effective words/s\n",
      "2018-11-29 16:47:29,176 : INFO : training on a 1424321 raw words (1035475 effective words) took 4.3s, 242067 effective words/s\n",
      "2018-11-29 16:47:29,200 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:29,201 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:30,229 : INFO : EPOCH 1 - PROGRESS: at 47.83% examples, 483426 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:31,285 : INFO : EPOCH 1 - PROGRESS: at 79.13% examples, 394288 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:31,797 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:31,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:31,841 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:31,846 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:31,850 : INFO : EPOCH - 1 : training on 1424321 raw words (1035707 effective words) took 2.6s, 392207 effective words/s\n",
      "2018-11-29 16:47:31,851 : INFO : training on a 1424321 raw words (1035707 effective words) took 2.6s, 391003 effective words/s\n",
      "2018-11-29 16:47:31,869 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:31,869 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:32,890 : INFO : EPOCH 1 - PROGRESS: at 31.41% examples, 322239 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:33,901 : INFO : EPOCH 1 - PROGRESS: at 63.08% examples, 326479 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:34,917 : INFO : EPOCH 1 - PROGRESS: at 97.00% examples, 331673 words/s, in_qsize 5, out_qsize 0\n",
      "2018-11-29 16:47:34,946 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:34,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:34,970 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:34,978 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:34,978 : INFO : EPOCH - 1 : training on 1424321 raw words (1035009 effective words) took 3.1s, 334733 effective words/s\n",
      "2018-11-29 16:47:34,979 : INFO : training on a 1424321 raw words (1035009 effective words) took 3.1s, 333997 effective words/s\n",
      "2018-11-29 16:47:34,998 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:35,004 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:36,008 : INFO : EPOCH 1 - PROGRESS: at 39.09% examples, 403297 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:37,022 : INFO : EPOCH 1 - PROGRESS: at 83.36% examples, 428450 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:37,396 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:37,423 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:37,430 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:37,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:37,440 : INFO : EPOCH - 1 : training on 1424321 raw words (1035052 effective words) took 2.4s, 426093 effective words/s\n",
      "2018-11-29 16:47:37,441 : INFO : training on a 1424321 raw words (1035052 effective words) took 2.4s, 424868 effective words/s\n",
      "2018-11-29 16:47:37,459 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:37,459 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:38,479 : INFO : EPOCH 1 - PROGRESS: at 33.73% examples, 344297 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:39,522 : INFO : EPOCH 1 - PROGRESS: at 65.13% examples, 328173 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:40,467 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:40,502 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:40,512 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:40,516 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:40,517 : INFO : EPOCH - 1 : training on 1424321 raw words (1035273 effective words) took 3.0s, 339896 effective words/s\n",
      "2018-11-29 16:47:40,518 : INFO : training on a 1424321 raw words (1035273 effective words) took 3.1s, 339198 effective words/s\n",
      "2018-11-29 16:47:40,532 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:40,538 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:41,549 : INFO : EPOCH 1 - PROGRESS: at 33.73% examples, 342701 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:42,594 : INFO : EPOCH 1 - PROGRESS: at 67.75% examples, 342402 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:43,367 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:43,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:43,391 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:43,397 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:43,399 : INFO : EPOCH - 1 : training on 1424321 raw words (1035210 effective words) took 2.9s, 362820 effective words/s\n",
      "2018-11-29 16:47:43,399 : INFO : training on a 1424321 raw words (1035210 effective words) took 2.9s, 361844 effective words/s\n",
      "2018-11-29 16:47:43,422 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:43,423 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:44,457 : INFO : EPOCH 1 - PROGRESS: at 20.86% examples, 210628 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:45,458 : INFO : EPOCH 1 - PROGRESS: at 39.80% examples, 202568 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:46,480 : INFO : EPOCH 1 - PROGRESS: at 56.41% examples, 191964 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:47,526 : INFO : EPOCH 1 - PROGRESS: at 75.50% examples, 190668 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:48,537 : INFO : EPOCH 1 - PROGRESS: at 94.24% examples, 191143 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:48,846 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:48,853 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:48,858 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:48,872 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 16:47:48,876 : INFO : EPOCH - 1 : training on 1424321 raw words (1035510 effective words) took 5.4s, 190150 effective words/s\n",
      "2018-11-29 16:47:48,878 : INFO : training on a 1424321 raw words (1035510 effective words) took 5.5s, 189861 effective words/s\n",
      "2018-11-29 16:47:48,932 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:48,932 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:49,957 : INFO : EPOCH 1 - PROGRESS: at 14.85% examples, 151606 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:50,969 : INFO : EPOCH 1 - PROGRESS: at 31.93% examples, 161650 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:51,977 : INFO : EPOCH 1 - PROGRESS: at 48.53% examples, 165103 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:52,986 : INFO : EPOCH 1 - PROGRESS: at 67.44% examples, 172461 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:54,002 : INFO : EPOCH 1 - PROGRESS: at 85.45% examples, 174861 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:54,652 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:54,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:54,666 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:54,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:54,684 : INFO : EPOCH - 1 : training on 1424321 raw words (1035370 effective words) took 5.7s, 180699 effective words/s\n",
      "2018-11-29 16:47:54,685 : INFO : training on a 1424321 raw words (1035370 effective words) took 5.8s, 180038 effective words/s\n",
      "2018-11-29 16:47:54,715 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:54,715 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:55,798 : INFO : EPOCH 1 - PROGRESS: at 31.59% examples, 303842 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:56,889 : INFO : EPOCH 1 - PROGRESS: at 51.45% examples, 244277 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:47:57,898 : INFO : EPOCH 1 - PROGRESS: at 73.53% examples, 239097 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:47:58,684 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:47:58,720 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:47:58,729 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:47:58,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:47:58,737 : INFO : EPOCH - 1 : training on 1424321 raw words (1035807 effective words) took 4.0s, 258227 effective words/s\n",
      "2018-11-29 16:47:58,738 : INFO : training on a 1424321 raw words (1035807 effective words) took 4.0s, 257822 effective words/s\n",
      "2018-11-29 16:47:58,765 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:47:58,765 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:47:59,851 : INFO : EPOCH 1 - PROGRESS: at 20.18% examples, 192747 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:48:00,867 : INFO : EPOCH 1 - PROGRESS: at 46.60% examples, 230444 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:48:01,919 : INFO : EPOCH 1 - PROGRESS: at 74.06% examples, 243129 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:48:02,820 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:48:02,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:48:02,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:48:02,862 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:48:02,867 : INFO : EPOCH - 1 : training on 1424321 raw words (1035141 effective words) took 4.1s, 252851 effective words/s\n",
      "2018-11-29 16:48:02,869 : INFO : training on a 1424321 raw words (1035141 effective words) took 4.1s, 252288 effective words/s\n",
      "2018-11-29 16:48:02,905 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:48:02,905 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:48:03,955 : INFO : EPOCH 1 - PROGRESS: at 20.11% examples, 201782 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:48:05,006 : INFO : EPOCH 1 - PROGRESS: at 42.49% examples, 210665 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:48:06,024 : INFO : EPOCH 1 - PROGRESS: at 65.22% examples, 216219 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:48:07,025 : INFO : EPOCH 1 - PROGRESS: at 87.42% examples, 219884 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:48:07,426 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:48:07,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:48:07,434 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:48:07,461 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:48:07,461 : INFO : EPOCH - 1 : training on 1424321 raw words (1035428 effective words) took 4.5s, 227733 effective words/s\n",
      "2018-11-29 16:48:07,461 : INFO : training on a 1424321 raw words (1035428 effective words) took 4.6s, 227272 effective words/s\n",
      "2018-11-29 16:48:07,494 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-11-29 16:48:07,494 : INFO : training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-11-29 16:48:08,593 : INFO : EPOCH 1 - PROGRESS: at 23.36% examples, 218967 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:48:09,661 : INFO : EPOCH 1 - PROGRESS: at 45.72% examples, 217710 words/s, in_qsize 8, out_qsize 0\n",
      "2018-11-29 16:48:10,695 : INFO : EPOCH 1 - PROGRESS: at 68.03% examples, 220264 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:48:11,714 : INFO : EPOCH 1 - PROGRESS: at 90.33% examples, 221533 words/s, in_qsize 7, out_qsize 0\n",
      "2018-11-29 16:48:12,068 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-29 16:48:12,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-29 16:48:12,108 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-29 16:48:12,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-29 16:48:12,126 : INFO : EPOCH - 1 : training on 1424321 raw words (1035695 effective words) took 4.6s, 224120 effective words/s\n",
      "2018-11-29 16:48:12,129 : INFO : training on a 1424321 raw words (1035695 effective words) took 4.6s, 223593 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# package for doc2vec\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "# for more parameters, check\n",
    "# https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "# initialize the model without documents\n",
    "# distributed memory model is used (dm=1)\n",
    "model = doc2vec.Doc2Vec(dm=1, min_count=5, window=5, size=200, workers=4)\n",
    "\n",
    "# build the vocabulary using the documents\n",
    "model.build_vocab(docs) \n",
    "\n",
    "# train the model in 20 epoches\n",
    "# You may need to incease epoches\n",
    "for epoch in range(30):\n",
    "    # shuffle the documents in each epoch\n",
    "    shuffle(docs)\n",
    "    # in each epoch, all samples are used\n",
    "    model.train(docs, total_examples=len(docs), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16183381,  0.12456312, -0.01335587, -0.42504102, -0.30003437,\n",
       "       -0.0140024 ,  0.03075002, -0.07262519,  0.16955574, -0.00588711,\n",
       "        0.13330661,  0.34285158,  0.03422689,  0.16842516, -0.25482705,\n",
       "       -0.19358243,  0.04123701, -0.13208947, -0.35571748,  0.12064377,\n",
       "       -0.30898485, -0.29411885, -0.16552879, -0.15874691,  0.04507516,\n",
       "       -0.04300391,  0.32410267,  0.013937  , -0.04040687, -0.29224434,\n",
       "       -0.04856979, -0.1116295 ,  0.00915188,  0.09112127, -0.2545681 ,\n",
       "       -0.3345861 , -0.07077353,  0.31784013,  0.04960489, -0.41506338,\n",
       "       -0.01637752, -0.22232306, -0.09818943, -0.33422542, -0.07733303,\n",
       "       -0.05552815,  0.13349698,  0.15030839, -0.15660381, -0.24477176,\n",
       "        0.07735987,  0.04587603, -0.14181733,  0.08060279,  0.04808345,\n",
       "       -0.10767551,  0.13980703, -0.10440759, -0.11982111,  0.12235789,\n",
       "       -0.16645856,  0.01852177, -0.00102426, -0.03302133,  0.05966326,\n",
       "       -0.36508772, -0.14287128,  0.21138044, -0.26033118,  0.12129605,\n",
       "        0.08976778,  0.19576767, -0.05471664,  0.01975648,  0.43221414,\n",
       "        0.10682452,  0.15065292,  0.03178932, -0.09301608,  0.02151372,\n",
       "        0.16667932,  0.16814029,  0.11884727, -0.0403614 ,  0.08739205,\n",
       "        0.16322318, -0.33150536, -0.16081755, -0.08069109,  0.09853979,\n",
       "       -0.2910754 , -0.0124069 ,  0.17236711, -0.06154401, -0.288048  ,\n",
       "       -0.09386825,  0.2912294 , -0.3563259 , -0.38864982,  0.3310266 ,\n",
       "        0.01427392,  0.12356894,  0.23026155, -0.12611575,  0.5078009 ,\n",
       "       -0.01169908,  0.11385526,  0.09270956,  0.35912213, -0.03354023,\n",
       "       -0.16012795,  0.02311128, -0.03141032, -0.1734618 ,  0.09177537,\n",
       "       -0.21226501, -0.10323358, -0.26189357, -0.07324238,  0.53196925,\n",
       "       -0.04308598, -0.06449925,  0.04209057,  0.20349883,  0.19346678,\n",
       "        0.070992  ,  0.05256363,  0.12019345,  0.04352941,  0.02662358,\n",
       "        0.00329227, -0.11965866, -0.04587132, -0.03493716,  0.0535812 ,\n",
       "       -0.18601915,  0.20363311, -0.43157324, -0.23161551,  0.03476121,\n",
       "        0.38796136,  0.13938986, -0.1796492 , -0.2045296 , -0.3020526 ,\n",
       "       -0.17713366, -0.13149856,  0.05133752, -0.33229393,  0.25970936,\n",
       "        0.18245725, -0.13282162, -0.09141342, -0.2143202 , -0.42059162,\n",
       "       -0.43859765, -0.19174923,  0.21275832,  0.00944428,  0.3506164 ,\n",
       "        0.04712678,  0.19682868, -0.19509597,  0.13725056,  0.39238638,\n",
       "        0.11430119,  0.19410567, -0.16083446,  0.06587894,  0.0285689 ,\n",
       "       -0.028165  , -0.08210553,  0.03016319,  0.32302228, -0.09624881,\n",
       "        0.02926478, -0.26510578,  0.1152316 , -0.30380827,  0.12677887,\n",
       "       -0.07169519, -0.6198438 , -0.357696  ,  0.38052362, -0.02103613,\n",
       "        0.3716604 ,  0.14247864, -0.06666965,  0.12678385, -0.37629774,\n",
       "        0.03782431, -0.05809937,  0.13957895, -0.35185707, -0.18117827,\n",
       "        0.00579353, -0.36504185,  0.19273318,  0.0403293 , -0.07180209],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.32080868, -0.44208628, -1.9293183 ,  0.52698386,  1.0503274 ,\n",
       "       -0.4278534 , -0.46762788, -1.185181  ,  0.94758856,  0.8573701 ,\n",
       "       -0.10250252, -0.44488475,  0.17767504,  0.33515498,  0.5420199 ,\n",
       "       -1.144247  ,  0.5452122 , -0.2690067 , -1.4898711 , -0.49906024,\n",
       "        1.3199672 ,  0.6627699 , -0.6692321 ,  0.12848899,  0.8057578 ,\n",
       "       -1.213073  , -2.3001816 ,  0.6786487 , -1.6315558 , -0.69076014,\n",
       "        1.2474767 ,  2.688198  , -0.4066019 , -0.6906432 , -1.6458328 ,\n",
       "       -0.4838479 , -0.22592361,  0.50402784,  2.0284889 ,  0.02295262,\n",
       "       -0.18683141, -0.06759565,  1.4908113 , -0.7008959 , -0.16842826,\n",
       "       -0.9167728 ,  1.3537824 , -0.72132736, -1.966232  ,  0.58001393,\n",
       "        0.235718  ,  1.2591712 ,  1.676096  , -0.00720707, -0.68636155,\n",
       "       -0.09933744, -0.63568777, -1.018072  ,  0.47194186, -0.61218387,\n",
       "        0.99325264,  0.13874184, -0.062783  ,  1.1817472 , -0.15142146,\n",
       "       -0.6144181 , -1.7649287 ,  0.53576696, -1.0139626 ,  0.9796524 ,\n",
       "       -1.1644771 , -0.68344426, -0.74336225,  1.6141788 ,  1.0560164 ,\n",
       "       -0.03256304,  2.0317523 , -0.14260624, -0.45038137,  1.848514  ,\n",
       "        0.8404191 , -0.6203046 , -0.067275  ,  0.14980055,  0.27271178,\n",
       "        0.32834882,  0.38893285,  0.36045647, -0.79050106, -0.5524573 ,\n",
       "        0.32633936, -0.03658831, -1.1070216 ,  0.6222119 , -1.773923  ,\n",
       "       -0.1484579 , -1.3019855 , -0.48654735,  0.11387898, -1.3481264 ,\n",
       "        0.02982681, -2.2456415 , -0.60968745,  0.4616796 , -0.5299024 ,\n",
       "        0.4219045 ,  1.3811265 , -0.49967077,  1.0561467 , -0.7880461 ,\n",
       "        0.4065135 ,  0.3652853 , -0.4802662 ,  0.19970217, -0.20216256,\n",
       "        0.27839452, -0.17768727,  0.2738623 ,  1.4785346 , -0.86936086,\n",
       "        0.6138955 , -0.8072331 , -0.10665742, -1.6639041 ,  0.872701  ,\n",
       "        0.15326138, -0.69102234, -0.71247363,  1.5169333 ,  1.3097624 ,\n",
       "       -1.2160581 ,  0.8250767 ,  0.49328578,  0.09200858, -0.37519982,\n",
       "        0.38998967,  0.41336524, -0.28360963,  1.4676125 , -2.259849  ,\n",
       "        0.20233826,  0.47153783, -1.0981681 , -0.47334275, -0.8716437 ,\n",
       "       -0.5021406 , -1.4393088 , -2.2639341 , -1.3701645 ,  0.23181465,\n",
       "       -0.68470883,  0.42660862, -1.0577153 ,  1.2044241 , -1.7349864 ,\n",
       "       -1.1685233 , -1.3469934 , -0.13052265,  0.34111783, -0.00976024,\n",
       "       -1.1178615 ,  1.4672929 , -0.5204701 , -1.6437451 ,  1.5688747 ,\n",
       "       -0.31005183,  0.30817533, -0.52944887, -0.32050443,  0.1693108 ,\n",
       "       -0.08643398,  1.147033  ,  0.19052649, -0.5054568 ,  0.07958519,\n",
       "        0.02251151, -1.3353446 ,  0.6874848 , -0.26753142, -0.55790126,\n",
       "        0.39676443,  1.4140972 ,  1.6589899 , -0.84850836,  0.3599535 ,\n",
       "       -0.17827247,  0.44097623,  0.08061384,  3.2280357 , -0.66111565,\n",
       "       -0.04238366, -1.7968224 ,  0.11930159,  1.6828778 ,  0.9030321 ,\n",
       "       -0.02051952, -0.6291989 ,  1.2638416 , -1.0686519 , -0.01532591],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect paragraph vectors and word vectors\n",
    "\n",
    "# the pragraph vector of the first document\n",
    "model.docvecs['0']\n",
    "\n",
    "# the word vector of 'movie'\n",
    "model.wv['movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-29 16:50:45,587 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('sounding', 0.4111652970314026),\n",
       " ('noise', 0.39860135316848755),\n",
       " ('sounds', 0.3959551453590393),\n",
       " ('camera', 0.3572186231613159),\n",
       " ('voice', 0.35401657223701477)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound' but not relevant to 'film'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('sounds', 0.3940489888191223),\n",
       " ('voice', 0.3609972298145294),\n",
       " ('noise', 0.34899282455444336),\n",
       " ('ballads', 0.34382694959640503),\n",
       " ('melodies', 0.3400244116783142)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'film':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66123486"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'city':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.045854423"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check word similarity\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound'\")\n",
    "model.wv.most_similar('sound', topn=5)\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound' but not relevant to 'film'\")\n",
    "model.wv.most_similar(positive=['sound','music'], negative=['film'], topn=5)\n",
    "\n",
    "print(\"Similarity between 'movie' and 'film':\")\n",
    "model.wv.similarity('movie','film') \n",
    "\n",
    "print(\"Similarity between 'movie' and 'city':\")\n",
    "model.wv.similarity('movie','city') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspect document similarity\n",
    "\n",
    "model.docvecs.most_similar('0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convolutional Neural Networks (CNN)\n",
    "References (**highly recommended**): \n",
    "- http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "- https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- CNNs are widely used in Computer Vision\n",
    "- CNNs were responsible for **major breakthroughs** in **Image Recognition** and are the core of most Computer Vision systems including automated photo tagging, self-driving cars\n",
    "- Recently, CNNs have been applied in NLP and achieved good performance.\n",
    "<img src='cnn.png' width='90%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Convolution\n",
    "- Convolution is the technique to **extract distinguishing features** from feature spaces\n",
    "- Example: feature detection from image pixels\n",
    "  - Feature space: a matrix of pixels of 0 (black) or 1 (white)\n",
    "  - **Filter/kernal/feature Detector**: a function applied to every fixed subset of the feature matrix\n",
    "    - e.g. 3x3 filter (a 3x3 matrix $\\begin{vmatrix}\n",
    "1 & 0 & 1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{vmatrix}$ ) slides through every area of the matrix sequentially, multiplies its values element-wise with the original matrix, then sum them up\n",
    "    - e.g. a filter (e.g. $\\begin{vmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "-1 & 4 & -1 \\\\\n",
    "0 & -1 & 0\n",
    "\\end{vmatrix}$ ) to take difference between a pixel and its neighbors --> detect edges\n",
    "    <img src='convolution.png' width=\"60%\">\n",
    "- Typically, a larger number of filters in different sizes will be used\n",
    "- Configuration of filters\n",
    "  - filter size ($h \\text{x} w$)\n",
    "  - stride size (how much to shift a filter in each step) ($s$)\n",
    "  - number of filters (depth) ($d$)\n",
    "- Questions: \n",
    "  - With 5x5 feature space, afte apply a filter of size 3x3 with stride size 2, what will be the size of the result? \n",
    "  - Formula to calculate the size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Pooling Layer\n",
    "- Pooling layers are typically applied after the convolutional layers. \n",
    "- A pooling layer subsamples its input. \n",
    "- The most common way to do pooling is to apply a **max** operation to the result of each filter (a.k.a 1-max pooling).\n",
    "  - e.g. for the example below, by 1-max pooling, we get 8.\n",
    "  - If 100 filters have been used, then we get 100 numbers\n",
    "- Pooling can be applied over a window (e.g. 2x2)\n",
    "<img src='max_pooling.png' width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. What are CNNs\n",
    "- CNNs consists of several layers of convolutions with nonlinear activation functions like ReLU or tanh \n",
    "\n",
    "<img src='cnn.png' width='70%'>\n",
    "\n",
    "- A CNN typically contains:\n",
    "  - A **convolution layer** (not dense layer) connected to the input layer\n",
    "      - Each convolution layer applies different filters. \n",
    "      - Typically hundreds or thousands filters used. \n",
    "      - The results of filters are concatenated.\n",
    "  - A **pooling layer** is used to subsample the result of convolution layer\n",
    "  - There may be multiple layers of convolution and pooling combined. E.g. image detection\n",
    "    - 1st layer: detect edges\n",
    "    - 2nd layer: detect shape, e.g. round, square\n",
    "    - 3rd layer: wheels, doors etc.\n",
    "  - Then each result out of convolution-pooling is connected to a neuron in the output (local connections). Such  results results are high-level features used by classification algorithms. \n",
    "- During the training phase, a CNN **automatically learns the values of its filters based on the task you want to perform**. \n",
    "- Powerful capabilities of CNN:\n",
    "  - **Location Invariance**: CNN extracts distinguishing features by convolution-pooling and it does not care where these features are. So images can still be recognized after rotation and scaling.\n",
    "  - **Compositionality**: Each filter composes a local patch of lower-level features into higher-level representation. E.g., detect edges from pixels, shapes from edges, and more complex objects from shapes. \n",
    "- If you're interested in how CNNs are used in image recognition, follow the classical <a href=\"https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\">MNIST handwritten digit recognition tutorial</a>\n",
    "- Play with it! http://scs.ryerson.ca/~aharley/vis/conv/flat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Application of CNN in Text Classification\n",
    "- Assume $m$ samples, each of which is a sentence with $n$ words (short sentences can be padded)\n",
    "- **Embedding**: In each sentence, each word can be represented as its word vector of dimension $d$ (pretrained or to be trained)\n",
    "- **Convolution**: Apply filters to n-grams of different lengths (e.g. unigram, bigrams, ...). \n",
    "   - E.g. A filter can slide through every 2 words (bigram)\n",
    "   - So, the filter size (i.e. region size) can be $1\\text{x}d$ (unigram), $2\\text{x}d$ (bigram), $3\\text{x}d$ (trigram), ...\n",
    "- At pooling layer, 1-max pooling is applied to the result of each filter. Then all results after pooling are concatenated as the input to the output layer\n",
    "  - This is equivalent to select words or phrases that are **discriminative** with regard to the classification goal\n",
    "\n",
    "<img src='cnn_text_classification.png' width='70%'>\n",
    "\n",
    "*Illustration of a Convolutional Neural Network (CNN) architecture for sentence classification. Here we depict three filter region sizes: 2, 3 and 4, each of which has 2 filters. Every filter performs convolution on the sentence matrix and generates (variable-length) feature maps. Then 1-max pooling is performed over each map, i.e., the largest number from each feature map is recorded. Thus a univariate feature vector is generated from all six maps, and these 6 features are concatenated to form a feature vector for the penultimate layer. The final softmax layer then receives this feature vector as input and uses it to classify the sentence; here we assume binary classification and hence depict two possible output states. Source: Zhang, Y., & Wallace, B. (2015). A Sensitivity Analysis of (and Practitioners Guide to) Convolutional Neural Networks for Sentence Classification.*\n",
    "\n",
    "- Questions:\n",
    "  - How many parameters in total in the convolution layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. How to deal with overfitting - Regularization & Dropout\n",
    "- Deep neural nets with a large number of parameters can be easily suffer from overfitting \n",
    "- Typical approaches to overcome overfitting\n",
    "    - Regularization\n",
    "    - Dropout (which is also a kind of regularization technique)\n",
    "- What is dropout?\n",
    "  - During training, randomly remove units in the hidden layer from the network. Update parameters as normal, leaving dropped-out units unchanged\n",
    "  - No dropout during testing \n",
    "  - Typically, each hidden unit is set to 0 with probability 0.5\n",
    "  <img src='dropout.png' width='60%'>\n",
    "  https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    " \n",
    "- Why dropout?\n",
    "  - Hidden units cannot co-adapt with other units since a unit may not always be present \n",
    "  - Sample data usually come with noise. Dropout constrains network adaptation to the data at training time\n",
    "  - After training, only very useful neurons are kept (have high weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6. Example: Use CNN for Sentiment Analysis (Single-Label Classification)\n",
    "- Dataset: IMDB review\n",
    "- 25,000 movie reviews, positive or negative \n",
    "- Benchmark performance is 80-90% with CNN (https://arxiv.org/abs/1408.5882)\n",
    "- We're going to create a CNN with the following:\n",
    "  - Word embedding trained as part of CNN\n",
    "  - filters in 3 sizes:\n",
    "      - unigram (Conv1D, kernel_size=1)\n",
    "      - bigram (Conv1D, kernel_size=2)\n",
    "      - trigram (Conv1D, kernel_size=3)\n",
    "  - Maxpooling for each convolution layer\n",
    "  - Dropout\n",
    "  <img src=\"cnn_model.png\" width='60%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.1: Load data\n",
    "\n",
    "import pandas as pd\n",
    "import nltk,string\n",
    "from gensim import corpora\n",
    "\n",
    "data=pd.read_csv(\"../../../dataset/imdb_reviews.csv\", header=0, delimiter=\"\\t\")\n",
    "data.head()\n",
    "len(data)\n",
    "\n",
    "# if your computer does not have enough resource\n",
    "# reduce the dataset\n",
    "data=data.loc[0:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.2 Prepocessing data: Tokenize, pad sentences\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "import numpy as np\n",
    "\n",
    "# set the maximum number of words to be used\n",
    "MAX_NB_WORDS=10000\n",
    "\n",
    "# set sentence/document length\n",
    "MAX_DOC_LEN=500\n",
    "\n",
    "# get a Keras tokenizer\n",
    "# https://keras.io/preprocessing/text/\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(data[\"review\"])\n",
    "\n",
    "# convert each document to a list of word index as a sequence\n",
    "sequences = tokenizer.texts_to_sequences(data[\"review\"])\n",
    "\n",
    "# pad all sequences into the same length \n",
    "# if a sentence is longer than maxlen, pad it in the right\n",
    "# if a sentence is shorter than maxlen, truncate it in the right\n",
    "padded_sequences = pad_sequences(sequences, \\\n",
    "                                 maxlen=MAX_DOC_LEN, \\\n",
    "                                 padding='post', \\\n",
    "                                 truncating='post')\n",
    "\n",
    "print(padded_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mapping between word and its index\n",
    "tokenizer.word_index['film']\n",
    "\n",
    "# get the count of each word\n",
    "tokenizer.word_counts['film']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                        padded_sequences, data['sentiment'],\\\n",
    "                        test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.3: Create CNN model\n",
    "\n",
    "from keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, \\\n",
    "Dropout, Activation, Input, Flatten, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# The dimension for embedding\n",
    "EMBEDDING_DIM=100\n",
    "\n",
    "# define input layer, where a sentence represented as\n",
    "# 1 dimension array with integers\n",
    "main_input = Input(shape=(MAX_DOC_LEN,), \\\n",
    "                   dtype='int32', name='main_input')\n",
    "\n",
    "# define the embedding layer\n",
    "# input_dim is the size of all words +1\n",
    "# where 1 is for the padding symbol\n",
    "# output_dim is the word vector dimension\n",
    "# input_length is the max. length of a document\n",
    "# input to embedding layer is the \"main_input\" layer\n",
    "embed_1 = Embedding(input_dim=MAX_NB_WORDS+1, \\\n",
    "                    output_dim=EMBEDDING_DIM, \\\n",
    "                    input_length=MAX_DOC_LEN,\\\n",
    "                    name='embedding')(main_input)\n",
    "\n",
    "\n",
    "# define 1D convolution layer\n",
    "# 64 filters are used\n",
    "# a filter slides through each word (kernel_size=1)\n",
    "# input to this layer is the embedding layer\n",
    "conv1d_1= Conv1D(filters=64, kernel_size=1, \\\n",
    "                 name='conv_unigram',\\\n",
    "                 activation='relu')(embed_1)\n",
    "\n",
    "# define a 1-dimension MaxPooling \n",
    "# to take the output of the previous convolution layer\n",
    "# the convolution layer produce \n",
    "# MAX_DOC_LEN-1+1 values as ouput (???)\n",
    "pool_1 = MaxPooling1D(MAX_DOC_LEN-1+1, \\\n",
    "                      name='pool_unigram')(conv1d_1)\n",
    "\n",
    "# The pooling layer creates output \n",
    "# in the size of (# of sample, 1, 64)  \n",
    "# remove one dimension since the size is 1\n",
    "flat_1 = Flatten(name='flat_unigram')(pool_1)\n",
    "\n",
    "# following the same logic to define \n",
    "# filters for bigram\n",
    "conv1d_2= Conv1D(filters=64, kernel_size=2, \\\n",
    "                 name='conv_bigram',\\\n",
    "                 activation='relu')(embed_1)\n",
    "pool_2 = MaxPooling1D(MAX_DOC_LEN-2+1, name='pool_bigram')(conv1d_2)\n",
    "flat_2 = Flatten(name='flat_bigram')(pool_2)\n",
    "\n",
    "# filters for trigram\n",
    "conv1d_3= Conv1D(filters=64, kernel_size=3, \\\n",
    "                 name='conv_trigram',activation='relu')(embed_1)\n",
    "pool_3 = MaxPooling1D(MAX_DOC_LEN-3+1, name='pool_trigram')(conv1d_3)\n",
    "flat_3 = Flatten(name='flat_trigram')(pool_3)\n",
    "\n",
    "# Concatenate flattened output\n",
    "z=Concatenate(name='concate')([flat_1, flat_2, flat_3])\n",
    "\n",
    "# Create a dropout layer\n",
    "# In each iteration only 50% units are turned on\n",
    "drop_1=Dropout(rate=0.5, name='dropout')(z)\n",
    "\n",
    "# Create a dense layer\n",
    "dense_1 = Dense(192, activation='relu', name='dense')(drop_1)\n",
    "# Create the output layer\n",
    "preds = Dense(1, activation='sigmoid', name='output')(dense_1)\n",
    "\n",
    "# create the model with input layer\n",
    "# and the output layer\n",
    "model = Model(inputs=main_input, outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.4: Show model configuration\n",
    "\n",
    "model.summary()\n",
    "#model.get_config()\n",
    "#model.get_weights()\n",
    "#from keras.utils import plot_model\n",
    "#plot_model(model, to_file='cnn_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.4: Compile the model\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", \\\n",
    "              optimizer=\"adam\", \\\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.5: Fit the model\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHES = 10\n",
    "\n",
    "# fit the model and save fitting history to \"training\"\n",
    "training=model.fit(X_train, y_train, \\\n",
    "                   batch_size=BATCH_SIZE, \\\n",
    "                   epochs=NUM_EPOCHES,\\\n",
    "                   validation_data=[X_test, y_test], \\\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.6. Investigate the training process\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# plot a figure with size 20x8\n",
    "\n",
    "# the fitting history is saved as dictionary\n",
    "# covert the dictionary to dataframe\n",
    "df=pd.DataFrame.from_dict(training.history)\n",
    "df.columns=[\"train_acc\", \"train_loss\", \\\n",
    "            \"val_acc\", \"val_loss\"]\n",
    "df.index.name='epoch'\n",
    "print(df)\n",
    "\n",
    "# plot training history\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8,3));\n",
    "\n",
    "df[[\"train_acc\", \"val_acc\"]].plot(ax=axes[0]);\n",
    "df[[\"train_loss\", \"val_loss\"]].plot(ax=axes[1]);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from training history:\n",
    "- As training goes on, training accuracy/loss gets always better\n",
    "- Testing accuracy/loss gets better at the beginning, the gets worse\n",
    "- This indicates that model is **overfitted** and cannot be generalized after certain point\n",
    "- Thus, we should **stop training the model when testing accuracy/loss gets worse**. \n",
    "- This analysis can be used to determine hyperparameter **NUM_EPOCHES**\n",
    "- Fortunately, this can be done automatically by **\"Early Stopping\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.6: Use early stopping to find the best model\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# the file path to save best model\n",
    "BEST_MODEL_FILEPATH=\"best_model\"\n",
    "\n",
    "# define early stopping based on validation loss\n",
    "# if validation loss is not improved in \n",
    "# an iteration compared with the previous one, \n",
    "# stop training (i.e. patience=0). \n",
    "# mode='min' indicate the loss needs to decrease \n",
    "earlyStopping=EarlyStopping(monitor='val_loss', \\\n",
    "                            patience=0, verbose=2, \\\n",
    "                            mode='min')\n",
    "\n",
    "# define checkpoint to save best model\n",
    "# which has max. validation acc\n",
    "checkpoint = ModelCheckpoint(BEST_MODEL_FILEPATH, \\\n",
    "                             monitor='val_acc', \\\n",
    "                             verbose=2, \\\n",
    "                             save_best_only=True, \\\n",
    "                             mode='max')\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"binary_crossentropy\", \\\n",
    "              optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# fit the model with earlystopping and checkpoint\n",
    "# as callbacks (functions that are executed as soon as \n",
    "# an asynchronous thread is completed)\n",
    "model.fit(X_train, y_train, \\\n",
    "          batch_size=BATCH_SIZE, epochs=NUM_EPOCHES, \\\n",
    "          callbacks=[earlyStopping, checkpoint],\n",
    "          validation_data=[X_test, y_test],\\\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.7: Load the best model\n",
    "\n",
    "# load the model using the save file\n",
    "model.load_weights(\"best_model\")\n",
    "\n",
    "# predict\n",
    "pred=model.predict(X_test)\n",
    "print(pred[0:5])\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 5.8: Put Everything as a function\n",
    "\n",
    "from keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, \\\n",
    "Dropout, Activation, Input, Flatten, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "              \n",
    "def cnn_model(FILTER_SIZES, \\\n",
    "              # filter sizes as a list\n",
    "              MAX_NB_WORDS, \\\n",
    "              # total number of words\n",
    "              MAX_DOC_LEN, \\\n",
    "              # max words in a doc\n",
    "              EMBEDDING_DIM=200, \\\n",
    "              # word vector dimension\n",
    "              NUM_FILTERS=64, \\\n",
    "              # number of filters for all size\n",
    "              DROP_OUT=0.5, \\\n",
    "              # dropout rate\n",
    "              NUM_OUTPUT_UNITS=1, \\\n",
    "              # number of output units\n",
    "              NUM_DENSE_UNITS=100,\\\n",
    "              # number of units in dense layer\n",
    "              PRETRAINED_WORD_VECTOR=None,\\\n",
    "              # Whether to use pretrained word vectors\n",
    "              LAM=0.0):            \n",
    "              # regularization coefficient\n",
    "    \n",
    "    main_input = Input(shape=(MAX_DOC_LEN,), \\\n",
    "                       dtype='int32', name='main_input')\n",
    "    \n",
    "    if PRETRAINED_WORD_VECTOR is not None:\n",
    "        embed_1 = Embedding(input_dim=MAX_NB_WORDS+1, \\\n",
    "                        output_dim=EMBEDDING_DIM, \\\n",
    "                        input_length=MAX_DOC_LEN, \\\n",
    "                        # use pretrained word vectors\n",
    "                        weights=[PRETRAINED_WORD_VECTOR],\\\n",
    "                        # word vectors can be further tuned\n",
    "                        # set it to False if use static word vectors\n",
    "                        trainable=True,\\\n",
    "                        name='embedding')(main_input)\n",
    "    else:\n",
    "        embed_1 = Embedding(input_dim=MAX_NB_WORDS+1, \\\n",
    "                        output_dim=EMBEDDING_DIM, \\\n",
    "                        input_length=MAX_DOC_LEN, \\\n",
    "                        name='embedding')(main_input)\n",
    "    # add convolution-pooling-flat block\n",
    "    conv_blocks = []\n",
    "    for f in FILTER_SIZES:\n",
    "        conv = Conv1D(filters=NUM_FILTERS, kernel_size=f, \\\n",
    "                      activation='relu', name='conv_'+str(f))(embed_1)\n",
    "        conv = MaxPooling1D(MAX_DOC_LEN-f+1, name='max_'+str(f))(conv)\n",
    "        conv = Flatten(name='flat_'+str(f))(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    \n",
    "    if len(conv_blocks)>1:\n",
    "        z=Concatenate(name='concate')(conv_blocks)\n",
    "    else:\n",
    "        z=conv_blocks[0]\n",
    "        \n",
    "    drop=Dropout(rate=DROP_OUT, name='dropout')(z)\n",
    "\n",
    "    dense = Dense(NUM_DENSE_UNITS, activation='relu',\\\n",
    "                    kernel_regularizer=l2(LAM),name='dense')(drop)\n",
    "    preds = Dense(NUM_OUTPUT_UNITS, activation='sigmoid', name='output')(dense)\n",
    "    model = Model(inputs=main_input, outputs=preds)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", \\\n",
    "              optimizer=\"adam\", metrics=[\"accuracy\"]) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7. Use CNN for multi-label classification\n",
    "- In multi-label classification, a document can be classified into multiple classes\n",
    "- We can use **multiple ouput units**, each responsible for predicating one class\n",
    "- For multi-label classification ($K$ classes), do the following:\n",
    "    1. Represent the labels as **indication matrix**\n",
    "        - e.g. three classes ['econ','biz','tech'] in total, \n",
    "        - sample 1: 'eco' only -> [1, 0, 0]\n",
    "        - sample 2: ['eco','biz'] ->[1, 1, 0]\n",
    "    2. Accordingly, **set output layer to have K output units**\n",
    "        - each responsible for one class\n",
    "        - each unit gives the probabability of one class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example: Yahoo News Ranked Multilabel Learning dataset (http://research.yahoo.com)\n",
    "  - A subset is selected\n",
    "  - 4 classes, 6426 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.7.1: Load and process the data\n",
    "\n",
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from numpy.random import shuffle\n",
    "\n",
    "# load the data\n",
    "data=json.load(open(\"../../dataset/ydata.json\",'rb'))\n",
    "#data=json.load(open(\"ydata.json\",'r'))\n",
    "\n",
    "\n",
    "# shuffle the data\n",
    "shuffle(data)\n",
    "\n",
    "# split into text and label\n",
    "text,labels=zip(*data)\n",
    "text=list(text)\n",
    "labels=list(labels)\n",
    "text[1]\n",
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.7.2: create indicator matrix for labels\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y=mlb.fit_transform(labels)\n",
    "# check size of indicator matrix\n",
    "Y.shape\n",
    "# check classes\n",
    "mlb.classes_\n",
    "# check # of samples in each class\n",
    "np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 5.7.3: Load and process the data\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "import numpy as np\n",
    "\n",
    "# get a Keras tokenizer\n",
    "\n",
    "MAX_NB_WORDS=8000\n",
    "# documents are quite long in the dataset\n",
    "MAX_DOC_LEN=1000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(text)\n",
    "voc=tokenizer.word_index\n",
    "# convert each document to a list of word index as a sequence\n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "# get the mapping between words to word index\n",
    "\n",
    "# pad all sequences into the same length (the longest)\n",
    "padded_sequences = pad_sequences(sequences, \\\n",
    "                                 maxlen=MAX_DOC_LEN, \\\n",
    "                                 padding='post', truncating='post')\n",
    "\n",
    "#print(padded_sequences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.7.4: Fit the model using the function\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EMBEDDING_DIM=100\n",
    "FILTER_SIZES=[2,3,4]\n",
    "\n",
    "# set the number of output units\n",
    "# as the number of classes\n",
    "output_units_num=len(mlb.classes_)\n",
    "num_filters=64\n",
    "\n",
    "# set the dense units\n",
    "dense_units_num= num_filters*len(FILTER_SIZES)\n",
    "\n",
    "\n",
    "BTACH_SIZE = 64\n",
    "NUM_EPOCHES = 20\n",
    "\n",
    "# split dataset into train (70%) and test sets (30%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "                padded_sequences, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "model=cnn_model(FILTER_SIZES, MAX_NB_WORDS, \\\n",
    "                MAX_DOC_LEN, \\\n",
    "                NUM_FILTERS=num_filters,\\\n",
    "                NUM_OUTPUT_UNITS=output_units_num, \\\n",
    "                NUM_DENSE_UNITS=dense_units_num)\n",
    "\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=0, verbose=2, mode='min')\n",
    "checkpoint = ModelCheckpoint(BEST_MODEL_FILEPATH, monitor='val_loss', \\\n",
    "                             verbose=2, save_best_only=True, mode='min')\n",
    "    \n",
    "training=model.fit(X_train, Y_train, \\\n",
    "          batch_size=BTACH_SIZE, epochs=NUM_EPOCHES, \\\n",
    "          callbacks=[earlyStopping, checkpoint],\\\n",
    "          validation_data=[X_test, Y_test], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.7.5: predicate using the best model\n",
    "# calculate performance\n",
    "\n",
    "# load the best model\n",
    "model.load_weights(\"best_model\")\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.7.6: Generate performance report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred=np.where(pred>0.5, 1, 0)\n",
    "\n",
    "print(classification_report(Y_test, pred,\\\n",
    "                      target_names=mlb.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8.  Use Pretrained Word Vectors\n",
    "- If **the size of labeled samples is small, it's better use pretrained word vectors** \n",
    "    - e.g. google or facebook pretrained word vectors\n",
    "    - or you can train word vectors using relevant context data using gensim\n",
    "- Procedure:\n",
    "    1. Obtain/train pretrained word vectors (see Section 4.1 and Exercise 4.1.1)\n",
    "    2. Look for the word vector for each word in the vocabulary and create **embedding matrix** where each row represents one word vector\n",
    "    3. Set embedding layer with the embedding matrix and set it not trainable.\n",
    "- With well-trained word vectors, often a small sample set can also achieve good performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 5.8.1: Load full yahoo news dataset\n",
    "# to train the word vector\n",
    "# note this data can be unlabeled. only text is used\n",
    "import json\n",
    "\n",
    "data=json.load(open(\"../../dataset/ydata_full.json\",'r'))\n",
    "text,labels=zip(*data)\n",
    "text=list(text)\n",
    "\n",
    "sentences=[ [token.strip(string.punctuation).strip() \\\n",
    "             for token in nltk.word_tokenize(doc) \\\n",
    "                 if token not in string.punctuation and \\\n",
    "                 len(token.strip(string.punctuation).strip())>=2]\\\n",
    "             for doc in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.8.2: Train word vector using \n",
    "# the large data set\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# print out tracking information\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \\\n",
    "                    level=logging.INFO)\n",
    "EMBEDDING_DIM=200\n",
    "# min_count: words with total frequency lower than this are ignored\n",
    "# size: the dimension of word vector\n",
    "# window: is the maximum distance \n",
    "#         between the current and predicted word \n",
    "#         within a sentence (i.e. the length of ngrams)\n",
    "# workers: # of parallel threads in training\n",
    "# for other parameters, check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "wv_model = word2vec.Word2Vec(sentences, \\\n",
    "                             min_count=5, \\\n",
    "                             size=EMBEDDING_DIM, \\\n",
    "                             window=5, workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get word vector for all words in the vocabulary\n",
    "# see reference at https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py\n",
    "\n",
    "EMBEDDING_DIM=200\n",
    "MAX_NB_WORDS=8000\n",
    "\n",
    "# tokenizer.word_index provides the mapping \n",
    "# between a word and word index for all words\n",
    "NUM_WORDS = min(MAX_NB_WORDS, len(tokenizer.word_index))\n",
    "\n",
    "# \"+1\" is for padding symbol\n",
    "embedding_matrix = np.zeros((NUM_WORDS+1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    # if word_index is above the max number of words, ignore it\n",
    "    if i >= NUM_WORDS:\n",
    "        continue\n",
    "    if word in wv_model.wv:\n",
    "        embedding_matrix[i]=wv_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.8.3: Fit model using pretrained word vectors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EMBEDDING_DIM=200\n",
    "FILTER_SIZES=[2,3,4]\n",
    "\n",
    "# set the number of output units\n",
    "# as the number of classes\n",
    "output_units_num=len(mlb.classes_)\n",
    "\n",
    "#Number of filters for each size\n",
    "num_filters=64\n",
    "\n",
    "# set the dense units\n",
    "dense_units_num= num_filters*len(FILTER_SIZES)\n",
    "\n",
    "BTACH_SIZE = 32\n",
    "NUM_EPOCHES = 100\n",
    "\n",
    "# With well trained word vectors, sample size can be reduced\n",
    "# Assume we only have 500 labeled data\n",
    "# split dataset into train (80%) and test sets (20%)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "                padded_sequences[0:500], Y[0:500], \\\n",
    "                test_size=0.2, random_state=0, \\\n",
    "                shuffle=True)\n",
    "\n",
    "# create the model with embedding matrix\n",
    "model=cnn_model(FILTER_SIZES, MAX_NB_WORDS, \\\n",
    "                MAX_DOC_LEN, \\\n",
    "                NUM_FILTERS=num_filters,\\\n",
    "                NUM_OUTPUT_UNITS=output_units_num, \\\n",
    "                NUM_DENSE_UNITS=dense_units_num,\\\n",
    "                PRETRAINED_WORD_VECTOR=embedding_matrix)\n",
    "\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=1, verbose=2, mode='min')\n",
    "checkpoint = ModelCheckpoint(BEST_MODEL_FILEPATH, monitor='val_loss', \\\n",
    "                             verbose=2, save_best_only=True, mode='min')\n",
    "    \n",
    "training=model.fit(X_train, Y_train, \\\n",
    "          batch_size=BTACH_SIZE, epochs=NUM_EPOCHES, \\\n",
    "          callbacks=[earlyStopping, checkpoint],\\\n",
    "          validation_data=[X_test, Y_test], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.8.4: check model configuration\n",
    "# Note that parameters from embedding layer\n",
    "# is not trainable\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.8.5: Performance evaluation\n",
    "# Let's use samples[500:1000]\n",
    "# as an evaluation set\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred=model.predict(padded_sequences[500:1000])\n",
    "\n",
    "Y_pred=np.copy(pred)\n",
    "Y_pred=np.where(Y_pred>0.5,1,0)\n",
    "\n",
    "Y_pred[0:10]\n",
    "Y[500:510]\n",
    "\n",
    "print(classification_report(Y[500:1000], \\\n",
    "                Y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Note that we only trained the model with **500 samples**\n",
    "- The performance is only slightly lower, compared with the one trained with 6000 samples\n",
    "- This shows that pre-trained word vectors can effectively improve the classification performance in the case of small labeled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9. How to select hyperparameters?\n",
    "- Fitting a neural network is a very empirical process\n",
    "- See Section 3 of \"Practical Recommendations for Gradient-Based Training of Deep Architectures\" (https://arxiv.org/abs/1206.5533) for detailed discussion\n",
    "- The following is some useful techniques to set \n",
    "  - MAX_NB_WORDS: max number words to be included in word embedding\n",
    "    - Based on word frequency histogram to include words that appear at least $n$ times\n",
    "  - MAX_DOC_LEN: max length of documents\n",
    "    - Based on document length frequency histogram to include complete sentences as many as possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.9.1 Set MAX_NB_WORDS to \n",
    "# include words that appear at least K times\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# get count of each word\n",
    "df=pd.DataFrame.from_dict(tokenizer.word_counts, \\\n",
    "                          orient=\"index\")\n",
    "df.columns=['freq']\n",
    "print(df.head())\n",
    "\n",
    "# get histogram of word count\n",
    "df=df['freq'].value_counts().reset_index()\n",
    "df.columns=['word_freq','count']\n",
    "\n",
    "# sort by word_freq\n",
    "df=df.sort_values(by='word_freq')\n",
    "\n",
    "# convert absolute counts to precentage\n",
    "df['percent']=df['count']/len(tokenizer.word_counts)\n",
    "# get cumulative percentage\n",
    "df['cumsum']=df['percent'].cumsum()\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.iloc[0:50].plot(x='word_freq', y='cumsum');\n",
    "\n",
    "plt.show();\n",
    "\n",
    "# if set min count for word to 10, \n",
    "# what % of words can be included?\n",
    "# how many words will be included?\n",
    "# This is the parameter MAX_NB_WORDS\n",
    "# tokenizer = Tokenizer(num_words=MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.9.2 Set MAX_DOC_LEN to \n",
    "# include complete sentences as many as possible\n",
    "\n",
    "# create a series based on the length of all sentences\n",
    "sen_len=pd.Series([len(item) for item in sequences])\n",
    "\n",
    "# create histogram of sentence length\n",
    "# the \"index\" is the sentence length\n",
    "# \"counts\" is the count of sentences at a length\n",
    "df=sen_len.value_counts().reset_index().sort_values(by='index')\n",
    "df.columns=['sent_length','counts']\n",
    "\n",
    "# sort by sentence length\n",
    "# get percentage and cumulative percentage\n",
    "\n",
    "df['percent']=df['counts']/len(sen_len)\n",
    "df['cumsum']=df['percent'].cumsum()\n",
    "print(df.head(3))\n",
    "\n",
    "# From the plot, 90% sentences have length<500\n",
    "# so it makes sense to set MAX_DOC_LEN=4~500 \n",
    "df.plot(x=\"sent_length\", y='cumsum');\n",
    "plt.show();\n",
    "\n",
    "# what will be the minimum sentence length\n",
    "# such that 99% of sentences will not be truncated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
